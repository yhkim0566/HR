{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nConfiguration Part.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Script to finetune AlexNet using Tensorflow.\n",
    "\n",
    "With this script you can finetune AlexNet as provided in the alexnet.py\n",
    "class on any given dataset. Specify the configuration settings at the\n",
    "beginning according to your problem.\n",
    "This script was written for TensorFlow >= version 1.2rc0 and comes with a blog\n",
    "post, which you can find here:\n",
    "\n",
    "https://kratzert.github.io/2017/02/24/finetuning-alexnet-with-tensorflow.html\n",
    "\n",
    "Author: Frederik Kratzert\n",
    "contact: f.kratzert(at)gmail.com\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "\n",
    "from alexnet import AlexNet\n",
    "from datagenerator import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "from tensorflow.contrib.data import Iterator\n",
    "\n",
    "\"\"\"\n",
    "Configuration Part.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the textfiles for the trainings and validation set\n",
    "train_file = './train.txt'\n",
    "val_file = './testoh.txt'\n",
    "\n",
    "# Learning params\n",
    "learning_rate = 0.02\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Network params\n",
    "dropout_rate = 0.5\n",
    "num_classes = 2\n",
    "train_layers = ['fc8', 'conv1']\n",
    "\n",
    "# How often we want to write the tf.summary data to disk\n",
    "display_step = 20\n",
    "\n",
    "# Path for tf.summary.FileWriter and to store model checkpoints\n",
    "filewriter_path = \"/tensorboard\"\n",
    "checkpoint_path = \"/checkpoints\"\n",
    "\n",
    "\"\"\"\n",
    "Main Part of the finetuning Script.\n",
    "\"\"\"\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)\n",
    "\n",
    "# Place data loading and preprocessing on the cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    tr_data = ImageDataGenerator(train_file,\n",
    "                                 mode='training',\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_classes=num_classes,\n",
    "                                 shuffle=True)\n",
    "    val_data = ImageDataGenerator(val_file,\n",
    "                                  mode='inference',\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_classes=num_classes,\n",
    "                                  shuffle=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an reinitializable iterator given the dataset structure\n",
    "iterator = Iterator.from_structure(tr_data.data.output_types,\n",
    "                                       tr_data.data.output_shapes)\n",
    "\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Ops for initializing the two different iterators\n",
    "training_init_op = iterator.make_initializer(tr_data.data)\n",
    "validation_init_op = iterator.make_initializer(val_data.data)\n",
    "\n",
    "# TF placeholder for graph input and output\n",
    "x = tf.placeholder(tf.float32, [batch_size, 227, 227, 3])\n",
    "y = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AlexNet(x, keep_prob, num_classes, train_layers)\n",
    "\n",
    "# Link variable to model output\n",
    "score = model.fc8\n",
    "\n",
    "# List of trainable variables of the layers we want to train\n",
    "var_list = [v for v in tf.trainable_variables() if v.name.split('/')[0] in train_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-ae74111bad46>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Summary name conv1/weights:0/gradient is illegal; using conv1/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0/gradient is illegal; using conv1/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0/gradient is illegal; using fc8/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0/gradient is illegal; using fc8/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/weights:0 is illegal; using conv1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0 is illegal; using conv1/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0 is illegal; using fc8/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0 is illegal; using fc8/biases_0 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Op for calculating the loss\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=score,\n",
    "                                                                  labels=y))\n",
    "\n",
    "# Train op\n",
    "with tf.name_scope(\"train\"):\n",
    "    # Get gradients of all trainable variables\n",
    "    gradients = tf.gradients(loss, var_list)\n",
    "    gradients = list(zip(gradients, var_list))\n",
    "\n",
    "    # Create optimizer and apply gradient descent to the trainable variables\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "\n",
    "# Add gradients to summary\n",
    "for gradient, var in gradients:\n",
    "    tf.summary.histogram(var.name + '/gradient', gradient)\n",
    "\n",
    "# Add the variables we train to the summary\n",
    "for var in var_list:\n",
    "    tf.summary.histogram(var.name, var)\n",
    "\n",
    "# Add the loss to summary\n",
    "tf.summary.scalar('cross_entropy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation op: Accuracy of the model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(score, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Add the accuracy to the summary\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(filewriter_path)\n",
    "\n",
    "# Initialize an saver for store model checkpoints\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Get the number of training/validation steps per epoch\n",
    "train_batches_per_epoch = int(np.floor(tr_data.data_size/batch_size))\n",
    "val_batches_per_epoch = int(np.floor(val_data.data_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:06:06.953478 Start training...\n",
      "2018-05-31 05:06:06.953582 Open Tensorboard at --logdir /tensorboard\n",
      "2018-05-31 05:06:06.953621 Epoch number: 1\n",
      "2018-05-31 05:06:10.647450 step\n",
      "2018-05-31 05:06:13.088569 step\n",
      "2018-05-31 05:06:15.496446 step\n",
      "2018-05-31 05:06:17.374623 Start validation\n",
      "2018-05-31 05:06:18.062373 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:06:18.062614 Saving checkpoint of model...\n",
      "2018-05-31 05:06:18.809007 Model checkpoint saved at /checkpoints/model_epoch1.ckpt\n",
      "2018-05-31 05:06:18.809125 Epoch number: 2\n",
      "2018-05-31 05:06:20.557288 step\n",
      "2018-05-31 05:06:22.966016 step\n",
      "2018-05-31 05:06:25.309132 step\n",
      "2018-05-31 05:06:27.218242 Start validation\n",
      "2018-05-31 05:06:27.624157 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:06:27.624298 Saving checkpoint of model...\n",
      "2018-05-31 05:06:28.167500 Model checkpoint saved at /checkpoints/model_epoch2.ckpt\n",
      "2018-05-31 05:06:28.167643 Epoch number: 3\n",
      "2018-05-31 05:06:29.923093 step\n",
      "2018-05-31 05:06:32.402381 step\n",
      "2018-05-31 05:06:34.946977 step\n",
      "2018-05-31 05:06:36.900600 Start validation\n",
      "2018-05-31 05:06:37.321412 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:06:37.321610 Saving checkpoint of model...\n",
      "2018-05-31 05:06:37.885123 Model checkpoint saved at /checkpoints/model_epoch3.ckpt\n",
      "2018-05-31 05:06:37.885242 Epoch number: 4\n",
      "2018-05-31 05:06:39.735665 step\n",
      "2018-05-31 05:06:42.129690 step\n",
      "2018-05-31 05:06:44.549414 step\n",
      "2018-05-31 05:06:46.478867 Start validation\n",
      "2018-05-31 05:06:46.938377 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:06:46.938611 Saving checkpoint of model...\n",
      "2018-05-31 05:06:47.499896 Model checkpoint saved at /checkpoints/model_epoch4.ckpt\n",
      "2018-05-31 05:06:47.500129 Epoch number: 5\n",
      "2018-05-31 05:06:49.312557 step\n",
      "2018-05-31 05:06:52.074749 step\n",
      "2018-05-31 05:06:54.566884 step\n",
      "2018-05-31 05:06:56.437213 Start validation\n",
      "2018-05-31 05:06:56.902208 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:06:56.902322 Saving checkpoint of model...\n",
      "2018-05-31 05:06:57.460325 Model checkpoint saved at /checkpoints/model_epoch5.ckpt\n",
      "2018-05-31 05:06:57.460808 Epoch number: 6\n",
      "2018-05-31 05:06:59.205033 step\n",
      "2018-05-31 05:07:01.656313 step\n",
      "2018-05-31 05:07:04.081631 step\n",
      "2018-05-31 05:07:06.092469 Start validation\n",
      "2018-05-31 05:07:06.543193 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:07:06.543396 Saving checkpoint of model...\n",
      "2018-05-31 05:07:07.155600 Model checkpoint saved at /checkpoints/model_epoch6.ckpt\n",
      "2018-05-31 05:07:07.155724 Epoch number: 7\n",
      "2018-05-31 05:07:09.003058 step\n",
      "2018-05-31 05:07:11.481777 step\n",
      "2018-05-31 05:07:14.040969 step\n",
      "2018-05-31 05:07:15.979658 Start validation\n",
      "2018-05-31 05:07:16.422888 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:07:16.423041 Saving checkpoint of model...\n",
      "2018-05-31 05:07:17.036293 Model checkpoint saved at /checkpoints/model_epoch7.ckpt\n",
      "2018-05-31 05:07:17.036412 Epoch number: 8\n",
      "2018-05-31 05:07:18.800156 step\n",
      "2018-05-31 05:07:21.234583 step\n",
      "2018-05-31 05:07:23.737907 step\n",
      "2018-05-31 05:07:25.725817 Start validation\n",
      "2018-05-31 05:07:26.161604 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:07:26.161794 Saving checkpoint of model...\n",
      "2018-05-31 05:07:26.775040 Model checkpoint saved at /checkpoints/model_epoch8.ckpt\n",
      "2018-05-31 05:07:26.775148 Epoch number: 9\n",
      "2018-05-31 05:07:28.535720 step\n",
      "2018-05-31 05:07:31.074759 step\n",
      "2018-05-31 05:07:33.624077 step\n",
      "2018-05-31 05:07:35.598670 Start validation\n",
      "2018-05-31 05:07:36.107159 Validation Accuracy = 0.6156\n",
      "2018-05-31 05:07:36.107358 Saving checkpoint of model...\n",
      "2018-05-31 05:07:36.721015 Model checkpoint saved at /checkpoints/model_epoch9.ckpt\n",
      "2018-05-31 05:07:36.721129 Epoch number: 10\n",
      "2018-05-31 05:07:38.592019 step\n",
      "2018-05-31 05:07:41.142878 step\n",
      "2018-05-31 05:07:43.677863 step\n",
      "2018-05-31 05:07:45.608855 Start validation\n",
      "2018-05-31 05:07:46.068232 Validation Accuracy = 0.5406\n",
      "2018-05-31 05:07:46.068441 Saving checkpoint of model...\n",
      "2018-05-31 05:07:46.661457 Model checkpoint saved at /checkpoints/model_epoch10.ckpt\n",
      "2018-05-31 05:07:46.661571 Epoch number: 11\n",
      "2018-05-31 05:07:48.423108 step\n",
      "2018-05-31 05:07:50.812787 step\n",
      "2018-05-31 05:07:53.275552 step\n",
      "2018-05-31 05:07:55.155444 Start validation\n",
      "2018-05-31 05:07:55.572933 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:07:55.573145 Saving checkpoint of model...\n",
      "2018-05-31 05:07:56.514684 Model checkpoint saved at /checkpoints/model_epoch11.ckpt\n",
      "2018-05-31 05:07:56.514831 Epoch number: 12\n",
      "2018-05-31 05:07:58.266328 step\n",
      "2018-05-31 05:08:00.597034 step\n",
      "2018-05-31 05:08:03.050922 step\n",
      "2018-05-31 05:08:04.927672 Start validation\n",
      "2018-05-31 05:08:05.343869 Validation Accuracy = 0.6781\n",
      "2018-05-31 05:08:05.344036 Saving checkpoint of model...\n",
      "2018-05-31 05:08:06.265869 Model checkpoint saved at /checkpoints/model_epoch12.ckpt\n",
      "2018-05-31 05:08:06.266393 Epoch number: 13\n",
      "2018-05-31 05:08:08.009509 step\n",
      "2018-05-31 05:08:10.416056 step\n",
      "2018-05-31 05:08:12.904518 step\n",
      "2018-05-31 05:08:14.836081 Start validation\n",
      "2018-05-31 05:08:15.258224 Validation Accuracy = 0.6531\n",
      "2018-05-31 05:08:15.258437 Saving checkpoint of model...\n",
      "2018-05-31 05:08:16.189683 Model checkpoint saved at /checkpoints/model_epoch13.ckpt\n",
      "2018-05-31 05:08:16.189794 Epoch number: 14\n",
      "2018-05-31 05:08:17.964413 step\n",
      "2018-05-31 05:08:20.346443 step\n",
      "2018-05-31 05:08:22.774704 step\n",
      "2018-05-31 05:08:24.688386 Start validation\n",
      "2018-05-31 05:08:25.107058 Validation Accuracy = 0.5938\n",
      "2018-05-31 05:08:25.107264 Saving checkpoint of model...\n",
      "2018-05-31 05:08:26.030559 Model checkpoint saved at /checkpoints/model_epoch14.ckpt\n",
      "2018-05-31 05:08:26.030709 Epoch number: 15\n",
      "2018-05-31 05:08:27.845641 step\n",
      "2018-05-31 05:08:30.209037 step\n",
      "2018-05-31 05:08:32.706400 step\n",
      "2018-05-31 05:08:34.761377 Start validation\n",
      "2018-05-31 05:08:35.191641 Validation Accuracy = 0.6438\n",
      "2018-05-31 05:08:35.191849 Saving checkpoint of model...\n",
      "2018-05-31 05:08:36.117829 Model checkpoint saved at /checkpoints/model_epoch15.ckpt\n",
      "2018-05-31 05:08:36.117978 Epoch number: 16\n",
      "2018-05-31 05:08:37.906679 step\n",
      "2018-05-31 05:08:40.564526 step\n",
      "2018-05-31 05:08:43.020410 step\n",
      "2018-05-31 05:08:44.922812 Start validation\n",
      "2018-05-31 05:08:45.332768 Validation Accuracy = 0.4813\n",
      "2018-05-31 05:08:45.332947 Saving checkpoint of model...\n",
      "2018-05-31 05:08:45.947464 Model checkpoint saved at /checkpoints/model_epoch16.ckpt\n",
      "2018-05-31 05:08:45.947584 Epoch number: 17\n",
      "2018-05-31 05:08:47.738100 step\n",
      "2018-05-31 05:08:50.175494 step\n",
      "2018-05-31 05:08:52.633381 step\n",
      "2018-05-31 05:08:54.563365 Start validation\n",
      "2018-05-31 05:08:55.023879 Validation Accuracy = 0.6062\n",
      "2018-05-31 05:08:55.024091 Saving checkpoint of model...\n",
      "2018-05-31 05:08:55.628640 Model checkpoint saved at /checkpoints/model_epoch17.ckpt\n",
      "2018-05-31 05:08:55.628747 Epoch number: 18\n",
      "2018-05-31 05:08:57.373616 step\n",
      "2018-05-31 05:08:59.899966 step\n",
      "2018-05-31 05:09:02.463668 step\n",
      "2018-05-31 05:09:04.491661 Start validation\n",
      "2018-05-31 05:09:04.930111 Validation Accuracy = 0.6719\n",
      "2018-05-31 05:09:04.930282 Saving checkpoint of model...\n",
      "2018-05-31 05:09:05.558727 Model checkpoint saved at /checkpoints/model_epoch18.ckpt\n",
      "2018-05-31 05:09:05.558832 Epoch number: 19\n",
      "2018-05-31 05:09:07.380939 step\n",
      "2018-05-31 05:09:09.849339 step\n",
      "2018-05-31 05:09:12.280325 step\n",
      "2018-05-31 05:09:14.172891 Start validation\n",
      "2018-05-31 05:09:14.593771 Validation Accuracy = 0.4844\n",
      "2018-05-31 05:09:14.593917 Saving checkpoint of model...\n",
      "2018-05-31 05:09:15.223246 Model checkpoint saved at /checkpoints/model_epoch19.ckpt\n",
      "2018-05-31 05:09:15.223798 Epoch number: 20\n",
      "2018-05-31 05:09:16.972045 step\n",
      "2018-05-31 05:09:19.399676 step\n",
      "2018-05-31 05:09:21.765846 step\n",
      "2018-05-31 05:09:23.692060 Start validation\n",
      "2018-05-31 05:09:24.154837 Validation Accuracy = 0.6813\n",
      "2018-05-31 05:09:24.155050 Saving checkpoint of model...\n",
      "2018-05-31 05:09:24.758193 Model checkpoint saved at /checkpoints/model_epoch20.ckpt\n",
      "2018-05-31 05:09:24.758297 Epoch number: 21\n",
      "2018-05-31 05:09:26.523499 step\n",
      "2018-05-31 05:09:28.908725 step\n",
      "2018-05-31 05:09:31.372610 step\n",
      "2018-05-31 05:09:33.282335 Start validation\n",
      "2018-05-31 05:09:33.737942 Validation Accuracy = 0.5687\n",
      "2018-05-31 05:09:33.738050 Saving checkpoint of model...\n",
      "2018-05-31 05:09:34.302109 Model checkpoint saved at /checkpoints/model_epoch21.ckpt\n",
      "2018-05-31 05:09:34.302216 Epoch number: 22\n",
      "2018-05-31 05:09:36.040162 step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:09:38.424515 step\n",
      "2018-05-31 05:09:40.871025 step\n",
      "2018-05-31 05:09:42.838270 Start validation\n",
      "2018-05-31 05:09:43.307990 Validation Accuracy = 0.5625\n",
      "2018-05-31 05:09:43.308195 Saving checkpoint of model...\n",
      "2018-05-31 05:09:43.916910 Model checkpoint saved at /checkpoints/model_epoch22.ckpt\n",
      "2018-05-31 05:09:43.917016 Epoch number: 23\n",
      "2018-05-31 05:09:45.677116 step\n",
      "2018-05-31 05:09:48.135530 step\n",
      "2018-05-31 05:09:50.760474 step\n",
      "2018-05-31 05:09:52.736749 Start validation\n",
      "2018-05-31 05:09:53.181938 Validation Accuracy = 0.4844\n",
      "2018-05-31 05:09:53.182575 Saving checkpoint of model...\n",
      "2018-05-31 05:09:53.807739 Model checkpoint saved at /checkpoints/model_epoch23.ckpt\n",
      "2018-05-31 05:09:53.807864 Epoch number: 24\n",
      "2018-05-31 05:09:55.706432 step\n",
      "2018-05-31 05:09:58.235124 step\n",
      "2018-05-31 05:10:00.937008 step\n",
      "2018-05-31 05:10:02.982756 Start validation\n",
      "2018-05-31 05:10:03.397204 Validation Accuracy = 0.5875\n",
      "2018-05-31 05:10:03.397435 Saving checkpoint of model...\n",
      "2018-05-31 05:10:04.020386 Model checkpoint saved at /checkpoints/model_epoch24.ckpt\n",
      "2018-05-31 05:10:04.020501 Epoch number: 25\n",
      "2018-05-31 05:10:05.775965 step\n",
      "2018-05-31 05:10:08.180794 step\n",
      "2018-05-31 05:10:10.648031 step\n",
      "2018-05-31 05:10:12.520425 Start validation\n",
      "2018-05-31 05:10:12.993151 Validation Accuracy = 0.6750\n",
      "2018-05-31 05:10:12.993324 Saving checkpoint of model...\n",
      "2018-05-31 05:10:13.609214 Model checkpoint saved at /checkpoints/model_epoch25.ckpt\n",
      "2018-05-31 05:10:13.609332 Epoch number: 26\n",
      "2018-05-31 05:10:15.401238 step\n",
      "2018-05-31 05:10:17.869585 step\n",
      "2018-05-31 05:10:20.273989 step\n",
      "2018-05-31 05:10:22.176180 Start validation\n",
      "2018-05-31 05:10:22.587202 Validation Accuracy = 0.6687\n",
      "2018-05-31 05:10:22.587415 Saving checkpoint of model...\n",
      "2018-05-31 05:10:23.485661 Model checkpoint saved at /checkpoints/model_epoch26.ckpt\n",
      "2018-05-31 05:10:23.485778 Epoch number: 27\n",
      "2018-05-31 05:10:25.222721 step\n",
      "2018-05-31 05:10:27.648427 step\n",
      "2018-05-31 05:10:30.069439 step\n",
      "2018-05-31 05:10:31.956260 Start validation\n",
      "2018-05-31 05:10:32.351913 Validation Accuracy = 0.6562\n",
      "2018-05-31 05:10:32.352059 Saving checkpoint of model...\n",
      "2018-05-31 05:10:33.200088 Model checkpoint saved at /checkpoints/model_epoch27.ckpt\n",
      "2018-05-31 05:10:33.200222 Epoch number: 28\n",
      "2018-05-31 05:10:34.981058 step\n",
      "2018-05-31 05:10:37.480580 step\n",
      "2018-05-31 05:10:39.881066 step\n",
      "2018-05-31 05:10:41.814122 Start validation\n",
      "2018-05-31 05:10:42.221379 Validation Accuracy = 0.5750\n",
      "2018-05-31 05:10:42.221511 Saving checkpoint of model...\n",
      "2018-05-31 05:10:43.148482 Model checkpoint saved at /checkpoints/model_epoch28.ckpt\n",
      "2018-05-31 05:10:43.148592 Epoch number: 29\n",
      "2018-05-31 05:10:44.925099 step\n",
      "2018-05-31 05:10:47.300161 step\n",
      "2018-05-31 05:10:49.763882 step\n",
      "2018-05-31 05:10:51.680649 Start validation\n",
      "2018-05-31 05:10:52.139325 Validation Accuracy = 0.6844\n",
      "2018-05-31 05:10:52.139580 Saving checkpoint of model...\n",
      "2018-05-31 05:10:53.071404 Model checkpoint saved at /checkpoints/model_epoch29.ckpt\n",
      "2018-05-31 05:10:53.071557 Epoch number: 30\n",
      "2018-05-31 05:10:54.811728 step\n",
      "2018-05-31 05:10:57.234774 step\n",
      "2018-05-31 05:10:59.662397 step\n",
      "2018-05-31 05:11:01.583691 Start validation\n",
      "2018-05-31 05:11:02.000039 Validation Accuracy = 0.6125\n",
      "2018-05-31 05:11:02.000482 Saving checkpoint of model...\n",
      "2018-05-31 05:11:02.929944 Model checkpoint saved at /checkpoints/model_epoch30.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Start Tensorflow session\n",
    "config=tf.ConfigProto(allow_soft_placement = True)\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # Load the pretrained weights into the non-trainable layer\n",
    "    model.load_initial_weights(sess)\n",
    "\n",
    "    print(\"{} Start training...\".format(datetime.now()))\n",
    "    print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(),\n",
    "                                                      filewriter_path))\n",
    "\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(\"{} Epoch number: {}\".format(datetime.now(), epoch+1))\n",
    "\n",
    "        # Initialize iterator with the training dataset\n",
    "        sess.run(training_init_op)\n",
    "\n",
    "        for step in range(train_batches_per_epoch):\n",
    "\n",
    "            # get next batch of data\n",
    "            img_batch, label_batch = sess.run(next_batch)       \n",
    "\n",
    "            # And run the training op\n",
    "            sess.run(train_op, feed_dict={x: img_batch,\n",
    "                                          y: label_batch,\n",
    "                                          keep_prob: dropout_rate})\n",
    "\n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            if step % display_step == 0:\n",
    "                s = sess.run(merged_summary, feed_dict={x: img_batch,\n",
    "                                                        y: label_batch,\n",
    "                                                        keep_prob: 1.})\n",
    "                writer.add_summary(s, epoch*train_batches_per_epoch + step)\n",
    "                print(\"{} step\".format(datetime.now(), step))\n",
    "\n",
    "        # Validate the model on the entire validation set\n",
    "        print(\"{} Start validation\".format(datetime.now()))\n",
    "        sess.run(validation_init_op)\n",
    "        test_acc = 0.\n",
    "        test_count = 0\n",
    "        for _ in range(val_batches_per_epoch):\n",
    "\n",
    "            img_batch, label_batch = sess.run(next_batch)\n",
    "            acc = sess.run(accuracy, feed_dict={x: img_batch,\n",
    "                                                y: label_batch,\n",
    "                                                keep_prob: 1.})\n",
    "            test_acc += acc\n",
    "            test_count += 1\n",
    "        test_acc /= test_count\n",
    "        print(\"{} Validation Accuracy = {:.4f}\".format(datetime.now(),\n",
    "                                                       test_acc))\n",
    "        print(\"{} Saving checkpoint of model...\".format(datetime.now()))\n",
    "\n",
    "        # save checkpoint of the model\n",
    "        checkpoint_name = os.path.join(checkpoint_path,\n",
    "                                       'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "        save_path = saver.save(sess, checkpoint_name)\n",
    "\n",
    "        print(\"{} Model checkpoint saved at {}\".format(datetime.now(),\n",
    "                                                       checkpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-13-f83d26d01220>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-f83d26d01220>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    temp_img = ev_data_sh[fail_idx[0][i]][:].reshape([480, 640, 3])\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    logits = tf.layers.dense(inputs=dropout_rate, units=2)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=val_data.labels, predictions=tf.argmax(input=logits, axis=1))}\n",
    "return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "\n",
    "\n",
    "ev_results = np.zeros((len(ev_label), 1))\n",
    "\n",
    "for i in range(len(ev_label)):\n",
    "        eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": ev_data_sh[i:i+1]},\n",
    "            y=ev_label_sh[i:i+1],\n",
    "            num_epochs=1,\n",
    "            shuffle=False)\n",
    "        eval_results = net_classifier.evaluate(input_fn=eval_input_fn)\n",
    "        ev_results[i] = eval_results[\"accuracy\"]\n",
    "        \n",
    "        \n",
    "fail_idx = np.where(ev_results == 0)\n",
    "print(fail_idx[0])\n",
    "print(len(fail_idx[0]))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "for i in range(len(fail_idx[0])):\n",
    "\n",
    "    temp_img = ev_data_sh[fail_idx[0][i]][:].reshape([480, 640, 3])\n",
    "\n",
    "    temp_img = 255-temp_img\n",
    "\n",
    "    width = 12\n",
    "    height = 12\n",
    "    plt.figure(figsize=(width, height))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
