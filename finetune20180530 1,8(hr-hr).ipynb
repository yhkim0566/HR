{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nConfiguration Part.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Script to finetune AlexNet using Tensorflow.\n",
    "\n",
    "With this script you can finetune AlexNet as provided in the alexnet.py\n",
    "class on any given dataset. Specify the configuration settings at the\n",
    "beginning according to your problem.\n",
    "This script was written for TensorFlow >= version 1.2rc0 and comes with a blog\n",
    "post, which you can find here:\n",
    "\n",
    "https://kratzert.github.io/2017/02/24/finetuning-alexnet-with-tensorflow.html\n",
    "\n",
    "Author: Frederik Kratzert\n",
    "contact: f.kratzert(at)gmail.com\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "\n",
    "from alexnet import AlexNet\n",
    "from datagenerator import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "from tensorflow.contrib.data import Iterator\n",
    "\n",
    "\"\"\"\n",
    "Configuration Part.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the textfiles for the trainings and validation set\n",
    "train_file = './trainhr.txt'\n",
    "val_file = './testhr.txt'\n",
    "\n",
    "# Learning params\n",
    "learning_rate = 0.02\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Network params\n",
    "dropout_rate = 0.5\n",
    "num_classes = 2\n",
    "train_layers = ['fc8', 'conv1']\n",
    "\n",
    "# How often we want to write the tf.summary data to disk\n",
    "display_step = 20\n",
    "\n",
    "# Path for tf.summary.FileWriter and to store model checkpoints\n",
    "filewriter_path = \"/tensorboard\"\n",
    "checkpoint_path = \"/checkpoints\"\n",
    "\n",
    "\"\"\"\n",
    "Main Part of the finetuning Script.\n",
    "\"\"\"\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)\n",
    "\n",
    "# Place data loading and preprocessing on the cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /temp/datagenerator.py:66: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with output_buffer_size is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with num_threads is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    tr_data = ImageDataGenerator(train_file,\n",
    "                                 mode='training',\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_classes=num_classes,\n",
    "                                 shuffle=True)\n",
    "    val_data = ImageDataGenerator(val_file,\n",
    "                                  mode='inference',\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_classes=num_classes,\n",
    "                                  shuffle=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an reinitializable iterator given the dataset structure\n",
    "iterator = Iterator.from_structure(tr_data.data.output_types,\n",
    "                                       tr_data.data.output_shapes)\n",
    "\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Ops for initializing the two different iterators\n",
    "training_init_op = iterator.make_initializer(tr_data.data)\n",
    "validation_init_op = iterator.make_initializer(val_data.data)\n",
    "\n",
    "# TF placeholder for graph input and output\n",
    "x = tf.placeholder(tf.float32, [batch_size, 227, 227, 3])\n",
    "y = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AlexNet(x, keep_prob, num_classes, train_layers)\n",
    "\n",
    "# Link variable to model output\n",
    "score = model.fc8\n",
    "\n",
    "# List of trainable variables of the layers we want to train\n",
    "var_list = [v for v in tf.trainable_variables() if v.name.split('/')[0] in train_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-ae74111bad46>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Summary name conv1/weights:0/gradient is illegal; using conv1/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0/gradient is illegal; using conv1/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0/gradient is illegal; using fc8/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0/gradient is illegal; using fc8/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/weights:0 is illegal; using conv1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0 is illegal; using conv1/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0 is illegal; using fc8/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0 is illegal; using fc8/biases_0 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Op for calculating the loss\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=score,\n",
    "                                                                  labels=y))\n",
    "\n",
    "# Train op\n",
    "with tf.name_scope(\"train\"):\n",
    "    # Get gradients of all trainable variables\n",
    "    gradients = tf.gradients(loss, var_list)\n",
    "    gradients = list(zip(gradients, var_list))\n",
    "\n",
    "    # Create optimizer and apply gradient descent to the trainable variables\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "\n",
    "# Add gradients to summary\n",
    "for gradient, var in gradients:\n",
    "    tf.summary.histogram(var.name + '/gradient', gradient)\n",
    "\n",
    "# Add the variables we train to the summary\n",
    "for var in var_list:\n",
    "    tf.summary.histogram(var.name, var)\n",
    "\n",
    "# Add the loss to summary\n",
    "tf.summary.scalar('cross_entropy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation op: Accuracy of the model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(score, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Add the accuracy to the summary\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(filewriter_path)\n",
    "\n",
    "# Initialize an saver for store model checkpoints\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Get the number of training/validation steps per epoch\n",
    "train_batches_per_epoch = int(np.floor(tr_data.data_size/batch_size))\n",
    "val_batches_per_epoch = int(np.floor(val_data.data_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:33:43.650858 Start training...\n",
      "2018-05-31 05:33:43.651259 Open Tensorboard at --logdir /tensorboard\n",
      "2018-05-31 05:33:43.651307 Epoch number: 1\n",
      "2018-05-31 05:33:47.187665 step\n",
      "2018-05-31 05:33:49.568849 step\n",
      "2018-05-31 05:33:52.041663 step\n",
      "2018-05-31 05:33:53.959955 Start validation\n",
      "2018-05-31 05:33:55.712898 Validation Accuracy = 0.5132\n",
      "2018-05-31 05:33:55.713089 Saving checkpoint of model...\n",
      "2018-05-31 05:33:56.407815 Model checkpoint saved at /checkpoints/model_epoch1.ckpt\n",
      "2018-05-31 05:33:56.407915 Epoch number: 2\n",
      "2018-05-31 05:33:58.209410 step\n",
      "2018-05-31 05:34:00.574242 step\n",
      "2018-05-31 05:34:03.048909 step\n",
      "2018-05-31 05:34:04.973939 Start validation\n",
      "2018-05-31 05:34:06.460490 Validation Accuracy = 0.8413\n",
      "2018-05-31 05:34:06.460627 Saving checkpoint of model...\n",
      "2018-05-31 05:34:06.940187 Model checkpoint saved at /checkpoints/model_epoch2.ckpt\n",
      "2018-05-31 05:34:06.940294 Epoch number: 3\n",
      "2018-05-31 05:34:08.739941 step\n",
      "2018-05-31 05:34:11.254362 step\n",
      "2018-05-31 05:34:13.770603 step\n",
      "2018-05-31 05:34:15.750521 Start validation\n",
      "2018-05-31 05:34:17.277246 Validation Accuracy = 0.7175\n",
      "2018-05-31 05:34:17.277350 Saving checkpoint of model...\n",
      "2018-05-31 05:34:17.776759 Model checkpoint saved at /checkpoints/model_epoch3.ckpt\n",
      "2018-05-31 05:34:17.776874 Epoch number: 4\n",
      "2018-05-31 05:34:19.528203 step\n",
      "2018-05-31 05:34:22.006977 step\n",
      "2018-05-31 05:34:24.510375 step\n",
      "2018-05-31 05:34:26.413668 Start validation\n",
      "2018-05-31 05:34:27.960367 Validation Accuracy = 0.8341\n",
      "2018-05-31 05:34:27.960551 Saving checkpoint of model...\n",
      "2018-05-31 05:34:28.467871 Model checkpoint saved at /checkpoints/model_epoch4.ckpt\n",
      "2018-05-31 05:34:28.467995 Epoch number: 5\n",
      "2018-05-31 05:34:30.358944 step\n",
      "2018-05-31 05:34:32.970707 step\n",
      "2018-05-31 05:34:35.679566 step\n",
      "2018-05-31 05:34:37.635272 Start validation\n",
      "2018-05-31 05:34:39.147939 Validation Accuracy = 0.7139\n",
      "2018-05-31 05:34:39.148054 Saving checkpoint of model...\n",
      "2018-05-31 05:34:39.637460 Model checkpoint saved at /checkpoints/model_epoch5.ckpt\n",
      "2018-05-31 05:34:39.637591 Epoch number: 6\n",
      "2018-05-31 05:34:41.499212 step\n",
      "2018-05-31 05:34:43.993592 step\n",
      "2018-05-31 05:34:46.482549 step\n",
      "2018-05-31 05:34:48.403317 Start validation\n",
      "2018-05-31 05:34:49.961871 Validation Accuracy = 0.8714\n",
      "2018-05-31 05:34:49.961977 Saving checkpoint of model...\n",
      "2018-05-31 05:34:50.523197 Model checkpoint saved at /checkpoints/model_epoch6.ckpt\n",
      "2018-05-31 05:34:50.523298 Epoch number: 7\n",
      "2018-05-31 05:34:52.332316 step\n",
      "2018-05-31 05:34:54.893552 step\n",
      "2018-05-31 05:34:57.461565 step\n",
      "2018-05-31 05:34:59.365490 Start validation\n",
      "2018-05-31 05:35:00.910689 Validation Accuracy = 0.8510\n",
      "2018-05-31 05:35:00.910800 Saving checkpoint of model...\n",
      "2018-05-31 05:35:01.460036 Model checkpoint saved at /checkpoints/model_epoch7.ckpt\n",
      "2018-05-31 05:35:01.460268 Epoch number: 8\n",
      "2018-05-31 05:35:03.294575 step\n",
      "2018-05-31 05:35:05.890290 step\n",
      "2018-05-31 05:35:08.325508 step\n",
      "2018-05-31 05:35:10.218294 Start validation\n",
      "2018-05-31 05:35:11.738979 Validation Accuracy = 0.8053\n",
      "2018-05-31 05:35:11.739092 Saving checkpoint of model...\n",
      "2018-05-31 05:35:12.313195 Model checkpoint saved at /checkpoints/model_epoch8.ckpt\n",
      "2018-05-31 05:35:12.313329 Epoch number: 9\n",
      "2018-05-31 05:35:14.123067 step\n",
      "2018-05-31 05:35:16.576489 step\n",
      "2018-05-31 05:35:19.099109 step\n",
      "2018-05-31 05:35:21.144556 Start validation\n",
      "2018-05-31 05:35:22.687854 Validation Accuracy = 0.8005\n",
      "2018-05-31 05:35:22.687982 Saving checkpoint of model...\n",
      "2018-05-31 05:35:23.242026 Model checkpoint saved at /checkpoints/model_epoch9.ckpt\n",
      "2018-05-31 05:35:23.242132 Epoch number: 10\n",
      "2018-05-31 05:35:25.094801 step\n",
      "2018-05-31 05:35:27.531013 step\n",
      "2018-05-31 05:35:29.911643 step\n",
      "2018-05-31 05:35:31.834180 Start validation\n",
      "2018-05-31 05:35:33.386034 Validation Accuracy = 0.7248\n",
      "2018-05-31 05:35:33.386154 Saving checkpoint of model...\n",
      "2018-05-31 05:35:33.944380 Model checkpoint saved at /checkpoints/model_epoch10.ckpt\n",
      "2018-05-31 05:35:33.944495 Epoch number: 11\n",
      "2018-05-31 05:35:35.737776 step\n",
      "2018-05-31 05:35:38.341978 step\n",
      "2018-05-31 05:35:40.929127 step\n",
      "2018-05-31 05:35:42.973196 Start validation\n",
      "2018-05-31 05:35:44.636397 Validation Accuracy = 0.8738\n",
      "2018-05-31 05:35:44.636516 Saving checkpoint of model...\n",
      "2018-05-31 05:35:45.185620 Model checkpoint saved at /checkpoints/model_epoch11.ckpt\n",
      "2018-05-31 05:35:45.185724 Epoch number: 12\n",
      "2018-05-31 05:35:46.995248 step\n",
      "2018-05-31 05:35:49.357356 step\n",
      "2018-05-31 05:35:51.708606 step\n",
      "2018-05-31 05:35:53.607317 Start validation\n",
      "2018-05-31 05:35:55.094979 Validation Accuracy = 0.7825\n",
      "2018-05-31 05:35:55.095108 Saving checkpoint of model...\n",
      "2018-05-31 05:35:55.663033 Model checkpoint saved at /checkpoints/model_epoch12.ckpt\n",
      "2018-05-31 05:35:55.663175 Epoch number: 13\n",
      "2018-05-31 05:35:57.462159 step\n",
      "2018-05-31 05:35:59.864454 step\n",
      "2018-05-31 05:36:02.238001 step\n",
      "2018-05-31 05:36:04.119180 Start validation\n",
      "2018-05-31 05:36:05.613544 Validation Accuracy = 0.7728\n",
      "2018-05-31 05:36:05.613668 Saving checkpoint of model...\n",
      "2018-05-31 05:36:06.156873 Model checkpoint saved at /checkpoints/model_epoch13.ckpt\n",
      "2018-05-31 05:36:06.156972 Epoch number: 14\n",
      "2018-05-31 05:36:07.913301 step\n",
      "2018-05-31 05:36:10.266904 step\n",
      "2018-05-31 05:36:12.702759 step\n",
      "2018-05-31 05:36:14.569089 Start validation\n",
      "2018-05-31 05:36:16.087226 Validation Accuracy = 0.8209\n",
      "2018-05-31 05:36:16.087335 Saving checkpoint of model...\n",
      "2018-05-31 05:36:16.718617 Model checkpoint saved at /checkpoints/model_epoch14.ckpt\n",
      "2018-05-31 05:36:16.718718 Epoch number: 15\n",
      "2018-05-31 05:36:18.493234 step\n",
      "2018-05-31 05:36:20.855710 step\n",
      "2018-05-31 05:36:23.270311 step\n",
      "2018-05-31 05:36:25.210981 Start validation\n",
      "2018-05-31 05:36:26.739786 Validation Accuracy = 0.7993\n",
      "2018-05-31 05:36:26.739929 Saving checkpoint of model...\n",
      "2018-05-31 05:36:27.312820 Model checkpoint saved at /checkpoints/model_epoch15.ckpt\n",
      "2018-05-31 05:36:27.313115 Epoch number: 16\n",
      "2018-05-31 05:36:29.101409 step\n",
      "2018-05-31 05:36:31.483489 step\n",
      "2018-05-31 05:36:33.911105 step\n",
      "2018-05-31 05:36:35.809715 Start validation\n",
      "2018-05-31 05:36:37.309629 Validation Accuracy = 0.7885\n",
      "2018-05-31 05:36:37.309756 Saving checkpoint of model...\n",
      "2018-05-31 05:36:37.862564 Model checkpoint saved at /checkpoints/model_epoch16.ckpt\n",
      "2018-05-31 05:36:37.862666 Epoch number: 17\n",
      "2018-05-31 05:36:39.630039 step\n",
      "2018-05-31 05:36:42.006923 step\n",
      "2018-05-31 05:36:44.484157 step\n",
      "2018-05-31 05:36:46.407069 Start validation\n",
      "2018-05-31 05:36:47.919123 Validation Accuracy = 0.7825\n",
      "2018-05-31 05:36:47.919240 Saving checkpoint of model...\n",
      "2018-05-31 05:36:48.466745 Model checkpoint saved at /checkpoints/model_epoch17.ckpt\n",
      "2018-05-31 05:36:48.466851 Epoch number: 18\n",
      "2018-05-31 05:36:50.225054 step\n",
      "2018-05-31 05:36:52.588149 step\n",
      "2018-05-31 05:36:54.990692 step\n",
      "2018-05-31 05:36:56.883301 Start validation\n",
      "2018-05-31 05:36:58.389092 Validation Accuracy = 0.8714\n",
      "2018-05-31 05:36:58.389206 Saving checkpoint of model...\n",
      "2018-05-31 05:36:58.965532 Model checkpoint saved at /checkpoints/model_epoch18.ckpt\n",
      "2018-05-31 05:36:58.965641 Epoch number: 19\n",
      "2018-05-31 05:37:00.720853 step\n",
      "2018-05-31 05:37:03.177651 step\n",
      "2018-05-31 05:37:05.699348 step\n",
      "2018-05-31 05:37:07.628994 Start validation\n",
      "2018-05-31 05:37:09.180719 Validation Accuracy = 0.7656\n",
      "2018-05-31 05:37:09.180847 Saving checkpoint of model...\n",
      "2018-05-31 05:37:09.741880 Model checkpoint saved at /checkpoints/model_epoch19.ckpt\n",
      "2018-05-31 05:37:09.742005 Epoch number: 20\n",
      "2018-05-31 05:37:11.578068 step\n",
      "2018-05-31 05:37:14.045815 step\n",
      "2018-05-31 05:37:16.644764 step\n",
      "2018-05-31 05:37:18.683925 Start validation\n",
      "2018-05-31 05:37:20.195498 Validation Accuracy = 0.8329\n",
      "2018-05-31 05:37:20.195621 Saving checkpoint of model...\n",
      "2018-05-31 05:37:20.738817 Model checkpoint saved at /checkpoints/model_epoch20.ckpt\n",
      "2018-05-31 05:37:20.738919 Epoch number: 21\n",
      "2018-05-31 05:37:22.548887 step\n",
      "2018-05-31 05:37:24.946185 step\n",
      "2018-05-31 05:37:27.345514 step\n",
      "2018-05-31 05:37:29.287156 Start validation\n",
      "2018-05-31 05:37:30.816753 Validation Accuracy = 0.7380\n",
      "2018-05-31 05:37:30.816867 Saving checkpoint of model...\n",
      "2018-05-31 05:37:31.393579 Model checkpoint saved at /checkpoints/model_epoch21.ckpt\n",
      "2018-05-31 05:37:31.393705 Epoch number: 22\n",
      "2018-05-31 05:37:33.130326 step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:37:35.531224 step\n",
      "2018-05-31 05:37:37.999180 step\n",
      "2018-05-31 05:37:39.957636 Start validation\n",
      "2018-05-31 05:37:41.472357 Validation Accuracy = 0.7728\n",
      "2018-05-31 05:37:41.472470 Saving checkpoint of model...\n",
      "2018-05-31 05:37:42.051243 Model checkpoint saved at /checkpoints/model_epoch22.ckpt\n",
      "2018-05-31 05:37:42.051369 Epoch number: 23\n",
      "2018-05-31 05:37:43.871281 step\n",
      "2018-05-31 05:37:46.311338 step\n",
      "2018-05-31 05:37:48.752407 step\n",
      "2018-05-31 05:37:50.653909 Start validation\n",
      "2018-05-31 05:37:52.175801 Validation Accuracy = 0.7981\n",
      "2018-05-31 05:37:52.175917 Saving checkpoint of model...\n",
      "2018-05-31 05:37:52.756430 Model checkpoint saved at /checkpoints/model_epoch23.ckpt\n",
      "2018-05-31 05:37:52.756544 Epoch number: 24\n",
      "2018-05-31 05:37:54.567564 step\n",
      "2018-05-31 05:37:57.178771 step\n",
      "2018-05-31 05:37:59.729090 step\n",
      "2018-05-31 05:38:01.639882 Start validation\n",
      "2018-05-31 05:38:03.199843 Validation Accuracy = 0.7103\n",
      "2018-05-31 05:38:03.199961 Saving checkpoint of model...\n",
      "2018-05-31 05:38:03.755887 Model checkpoint saved at /checkpoints/model_epoch24.ckpt\n",
      "2018-05-31 05:38:03.755987 Epoch number: 25\n",
      "2018-05-31 05:38:05.581640 step\n",
      "2018-05-31 05:38:07.960043 step\n",
      "2018-05-31 05:38:10.454581 step\n",
      "2018-05-31 05:38:12.380816 Start validation\n",
      "2018-05-31 05:38:13.942043 Validation Accuracy = 0.8017\n",
      "2018-05-31 05:38:13.942172 Saving checkpoint of model...\n",
      "2018-05-31 05:38:14.512536 Model checkpoint saved at /checkpoints/model_epoch25.ckpt\n",
      "2018-05-31 05:38:14.512679 Epoch number: 26\n",
      "2018-05-31 05:38:16.360658 step\n",
      "2018-05-31 05:38:18.909974 step\n",
      "2018-05-31 05:38:21.400756 step\n",
      "2018-05-31 05:38:23.321445 Start validation\n",
      "2018-05-31 05:38:24.909983 Validation Accuracy = 0.8077\n",
      "2018-05-31 05:38:24.910115 Saving checkpoint of model...\n",
      "2018-05-31 05:38:25.735129 Model checkpoint saved at /checkpoints/model_epoch26.ckpt\n",
      "2018-05-31 05:38:25.735247 Epoch number: 27\n",
      "2018-05-31 05:38:27.562724 step\n",
      "2018-05-31 05:38:30.046968 step\n",
      "2018-05-31 05:38:32.426483 step\n",
      "2018-05-31 05:38:34.364431 Start validation\n",
      "2018-05-31 05:38:35.887757 Validation Accuracy = 0.8341\n",
      "2018-05-31 05:38:35.887889 Saving checkpoint of model...\n",
      "2018-05-31 05:38:36.762914 Model checkpoint saved at /checkpoints/model_epoch27.ckpt\n",
      "2018-05-31 05:38:36.763034 Epoch number: 28\n",
      "2018-05-31 05:38:38.583672 step\n",
      "2018-05-31 05:38:41.143430 step\n",
      "2018-05-31 05:38:43.656158 step\n",
      "2018-05-31 05:38:45.647478 Start validation\n",
      "2018-05-31 05:38:47.165155 Validation Accuracy = 0.7200\n",
      "2018-05-31 05:38:47.165274 Saving checkpoint of model...\n",
      "2018-05-31 05:38:47.899103 Model checkpoint saved at /checkpoints/model_epoch28.ckpt\n",
      "2018-05-31 05:38:47.899255 Epoch number: 29\n",
      "2018-05-31 05:38:49.688953 step\n",
      "2018-05-31 05:38:52.055800 step\n",
      "2018-05-31 05:38:54.584156 step\n",
      "2018-05-31 05:38:56.575978 Start validation\n",
      "2018-05-31 05:38:58.116248 Validation Accuracy = 0.7548\n",
      "2018-05-31 05:38:58.116384 Saving checkpoint of model...\n",
      "2018-05-31 05:38:58.973232 Model checkpoint saved at /checkpoints/model_epoch29.ckpt\n",
      "2018-05-31 05:38:58.973364 Epoch number: 30\n",
      "2018-05-31 05:39:00.780300 step\n",
      "2018-05-31 05:39:03.315035 step\n",
      "2018-05-31 05:39:05.780931 step\n",
      "2018-05-31 05:39:07.802533 Start validation\n",
      "2018-05-31 05:39:09.445223 Validation Accuracy = 0.8305\n",
      "2018-05-31 05:39:09.445376 Saving checkpoint of model...\n",
      "2018-05-31 05:39:10.315447 Model checkpoint saved at /checkpoints/model_epoch30.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Start Tensorflow session\n",
    "config=tf.ConfigProto(allow_soft_placement = True)\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # Load the pretrained weights into the non-trainable layer\n",
    "    model.load_initial_weights(sess)\n",
    "\n",
    "    print(\"{} Start training...\".format(datetime.now()))\n",
    "    print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(),\n",
    "                                                      filewriter_path))\n",
    "\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(\"{} Epoch number: {}\".format(datetime.now(), epoch+1))\n",
    "\n",
    "        # Initialize iterator with the training dataset\n",
    "        sess.run(training_init_op)\n",
    "\n",
    "        for step in range(train_batches_per_epoch):\n",
    "\n",
    "            # get next batch of data\n",
    "            img_batch, label_batch = sess.run(next_batch)       \n",
    "\n",
    "            # And run the training op\n",
    "            sess.run(train_op, feed_dict={x: img_batch,\n",
    "                                          y: label_batch,\n",
    "                                          keep_prob: dropout_rate})\n",
    "\n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            if step % display_step == 0:\n",
    "                s = sess.run(merged_summary, feed_dict={x: img_batch,\n",
    "                                                        y: label_batch,\n",
    "                                                        keep_prob: 1.})\n",
    "                writer.add_summary(s, epoch*train_batches_per_epoch + step)\n",
    "                print(\"{} step\".format(datetime.now(), step))\n",
    "\n",
    "        # Validate the model on the entire validation set\n",
    "        print(\"{} Start validation\".format(datetime.now()))\n",
    "        sess.run(validation_init_op)\n",
    "        test_acc = 0.\n",
    "        test_count = 0\n",
    "        for _ in range(val_batches_per_epoch):\n",
    "\n",
    "            img_batch, label_batch = sess.run(next_batch)\n",
    "            acc = sess.run(accuracy, feed_dict={x: img_batch,\n",
    "                                                y: label_batch,\n",
    "                                                keep_prob: 1.})\n",
    "            test_acc += acc\n",
    "            test_count += 1\n",
    "        test_acc /= test_count\n",
    "        print(\"{} Validation Accuracy = {:.4f}\".format(datetime.now(),\n",
    "                                                       test_acc))\n",
    "        print(\"{} Saving checkpoint of model...\".format(datetime.now()))\n",
    "\n",
    "        # save checkpoint of the model\n",
    "        checkpoint_name = os.path.join(checkpoint_path,\n",
    "                                       'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "        save_path = saver.save(sess, checkpoint_name)\n",
    "\n",
    "        print(\"{} Model checkpoint saved at {}\".format(datetime.now(),\n",
    "                                                       checkpoint_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
