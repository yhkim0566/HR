{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nConfiguration Part.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Script to finetune AlexNet using Tensorflow.\n",
    "\n",
    "With this script you can finetune AlexNet as provided in the alexnet.py\n",
    "class on any given dataset. Specify the configuration settings at the\n",
    "beginning according to your problem.\n",
    "This script was written for TensorFlow >= version 1.2rc0 and comes with a blog\n",
    "post, which you can find here:\n",
    "\n",
    "https://kratzert.github.io/2017/02/24/finetuning-alexnet-with-tensorflow.html\n",
    "\n",
    "Author: Frederik Kratzert\n",
    "contact: f.kratzert(at)gmail.com\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "\n",
    "from alexnet import AlexNet\n",
    "from datagenerator import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "from tensorflow.contrib.data import Iterator\n",
    "\n",
    "\"\"\"\n",
    "Configuration Part.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the textfiles for the trainings and validation set\n",
    "train_file = './trainhr.txt'\n",
    "val_file = './testhr.txt'\n",
    "\n",
    "# Learning params\n",
    "learning_rate = 0.02\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Network params\n",
    "dropout_rate = 0.5\n",
    "num_classes = 2\n",
    "train_layers = ['fc8','fc7','fc6','conv1']\n",
    "\n",
    "# How often we want to write the tf.summary data to disk\n",
    "display_step = 20\n",
    "\n",
    "# Path for tf.summary.FileWriter and to store model checkpoints\n",
    "filewriter_path = \"/tensorboard\"\n",
    "checkpoint_path = \"/checkpoints\"\n",
    "\n",
    "\"\"\"\n",
    "Main Part of the finetuning Script.\n",
    "\"\"\"\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)\n",
    "\n",
    "# Place data loading and preprocessing on the cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /temp/datagenerator.py:66: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with num_threads is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with output_buffer_size is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    tr_data = ImageDataGenerator(train_file,\n",
    "                                 mode='training',\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_classes=num_classes,\n",
    "                                 shuffle=True)\n",
    "    val_data = ImageDataGenerator(val_file,\n",
    "                                  mode='inference',\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_classes=num_classes,\n",
    "                                  shuffle=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an reinitializable iterator given the dataset structure\n",
    "iterator = Iterator.from_structure(tr_data.data.output_types,\n",
    "                                       tr_data.data.output_shapes)\n",
    "\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Ops for initializing the two different iterators\n",
    "training_init_op = iterator.make_initializer(tr_data.data)\n",
    "validation_init_op = iterator.make_initializer(val_data.data)\n",
    "\n",
    "# TF placeholder for graph input and output\n",
    "x = tf.placeholder(tf.float32, [batch_size, 227, 227, 3])\n",
    "y = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AlexNet(x, keep_prob, num_classes, train_layers)\n",
    "\n",
    "# Link variable to model output\n",
    "score = model.fc8\n",
    "\n",
    "# List of trainable variables of the layers we want to train\n",
    "var_list = [v for v in tf.trainable_variables() if v.name.split('/')[0] in train_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-ae74111bad46>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Summary name conv1/weights:0/gradient is illegal; using conv1/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0/gradient is illegal; using conv1/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc6/weights:0/gradient is illegal; using fc6/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc6/biases:0/gradient is illegal; using fc6/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/weights:0/gradient is illegal; using fc7/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0/gradient is illegal; using fc7/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0/gradient is illegal; using fc8/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0/gradient is illegal; using fc8/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/weights:0 is illegal; using conv1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0 is illegal; using conv1/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc6/weights:0 is illegal; using fc6/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc6/biases:0 is illegal; using fc6/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc7/weights:0 is illegal; using fc7/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0 is illegal; using fc7/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0 is illegal; using fc8/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0 is illegal; using fc8/biases_0 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Op for calculating the loss\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=score,\n",
    "                                                                  labels=y))\n",
    "\n",
    "# Train op\n",
    "with tf.name_scope(\"train\"):\n",
    "    # Get gradients of all trainable variables\n",
    "    gradients = tf.gradients(loss, var_list)\n",
    "    gradients = list(zip(gradients, var_list))\n",
    "\n",
    "    # Create optimizer and apply gradient descent to the trainable variables\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "\n",
    "# Add gradients to summary\n",
    "for gradient, var in gradients:\n",
    "    tf.summary.histogram(var.name + '/gradient', gradient)\n",
    "\n",
    "# Add the variables we train to the summary\n",
    "for var in var_list:\n",
    "    tf.summary.histogram(var.name, var)\n",
    "\n",
    "# Add the loss to summary\n",
    "tf.summary.scalar('cross_entropy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation op: Accuracy of the model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(score, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Add the accuracy to the summary\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(filewriter_path)\n",
    "\n",
    "# Initialize an saver for store model checkpoints\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Get the number of training/validation steps per epoch\n",
    "train_batches_per_epoch = int(np.floor(tr_data.data_size/batch_size))\n",
    "val_batches_per_epoch = int(np.floor(val_data.data_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:48:07.098662 Start training...\n",
      "2018-05-31 05:48:07.098777 Open Tensorboard at --logdir /tensorboard\n",
      "2018-05-31 05:48:07.098830 Epoch number: 1\n",
      "2018-05-31 05:48:12.027775 step\n",
      "2018-05-31 05:48:15.915181 step\n",
      "2018-05-31 05:48:19.816559 step\n",
      "2018-05-31 05:48:21.818185 Start validation\n",
      "2018-05-31 05:48:23.420512 Validation Accuracy = 0.6106\n",
      "2018-05-31 05:48:23.420642 Saving checkpoint of model...\n",
      "2018-05-31 05:48:23.655274 Model checkpoint saved at /checkpoints/model_epoch1.ckpt\n",
      "2018-05-31 05:48:23.655692 Epoch number: 2\n",
      "2018-05-31 05:48:27.110001 step\n",
      "2018-05-31 05:48:31.057849 step\n",
      "2018-05-31 05:48:34.935345 step\n",
      "2018-05-31 05:48:36.887395 Start validation\n",
      "2018-05-31 05:48:38.419997 Validation Accuracy = 0.6839\n",
      "2018-05-31 05:48:38.420444 Saving checkpoint of model...\n",
      "2018-05-31 05:48:38.644333 Model checkpoint saved at /checkpoints/model_epoch2.ckpt\n",
      "2018-05-31 05:48:38.644807 Epoch number: 3\n",
      "2018-05-31 05:48:42.160331 step\n",
      "2018-05-31 05:48:46.076066 step\n",
      "2018-05-31 05:48:49.798951 step\n",
      "2018-05-31 05:48:51.739901 Start validation\n",
      "2018-05-31 05:48:53.275097 Validation Accuracy = 0.8329\n",
      "2018-05-31 05:48:53.275291 Saving checkpoint of model...\n",
      "2018-05-31 05:48:53.475847 Model checkpoint saved at /checkpoints/model_epoch3.ckpt\n",
      "2018-05-31 05:48:53.476035 Epoch number: 4\n",
      "2018-05-31 05:48:56.923259 step\n",
      "2018-05-31 05:49:00.744864 step\n",
      "2018-05-31 05:49:04.537252 step\n",
      "2018-05-31 05:49:06.498819 Start validation\n",
      "2018-05-31 05:49:07.997131 Validation Accuracy = 0.8401\n",
      "2018-05-31 05:49:07.997234 Saving checkpoint of model...\n",
      "2018-05-31 05:49:08.223584 Model checkpoint saved at /checkpoints/model_epoch4.ckpt\n",
      "2018-05-31 05:49:08.223771 Epoch number: 5\n",
      "2018-05-31 05:49:11.696134 step\n",
      "2018-05-31 05:49:15.385684 step\n",
      "2018-05-31 05:49:19.132468 step\n",
      "2018-05-31 05:49:21.059572 Start validation\n",
      "2018-05-31 05:49:22.541421 Validation Accuracy = 0.7560\n",
      "2018-05-31 05:49:22.541569 Saving checkpoint of model...\n",
      "2018-05-31 05:49:22.760294 Model checkpoint saved at /checkpoints/model_epoch5.ckpt\n",
      "2018-05-31 05:49:22.760534 Epoch number: 6\n",
      "2018-05-31 05:49:26.207877 step\n",
      "2018-05-31 05:49:29.879278 step\n",
      "2018-05-31 05:49:33.639851 step\n",
      "2018-05-31 05:49:35.567022 Start validation\n",
      "2018-05-31 05:49:37.054915 Validation Accuracy = 0.8317\n",
      "2018-05-31 05:49:37.055071 Saving checkpoint of model...\n",
      "2018-05-31 05:49:37.285794 Model checkpoint saved at /checkpoints/model_epoch6.ckpt\n",
      "2018-05-31 05:49:37.285987 Epoch number: 7\n",
      "2018-05-31 05:49:40.746195 step\n",
      "2018-05-31 05:49:44.378990 step\n",
      "2018-05-31 05:49:48.121441 step\n",
      "2018-05-31 05:49:50.053662 Start validation\n",
      "2018-05-31 05:49:51.507445 Validation Accuracy = 0.7464\n",
      "2018-05-31 05:49:51.507562 Saving checkpoint of model...\n",
      "2018-05-31 05:49:51.752163 Model checkpoint saved at /checkpoints/model_epoch7.ckpt\n",
      "2018-05-31 05:49:51.752512 Epoch number: 8\n",
      "2018-05-31 05:49:55.144655 step\n",
      "2018-05-31 05:49:58.763745 step\n",
      "2018-05-31 05:50:02.509303 step\n",
      "2018-05-31 05:50:04.449146 Start validation\n",
      "2018-05-31 05:50:05.945431 Validation Accuracy = 0.8377\n",
      "2018-05-31 05:50:05.945549 Saving checkpoint of model...\n",
      "2018-05-31 05:50:06.183781 Model checkpoint saved at /checkpoints/model_epoch8.ckpt\n",
      "2018-05-31 05:50:06.184008 Epoch number: 9\n",
      "2018-05-31 05:50:09.745310 step\n",
      "2018-05-31 05:50:13.355317 step\n",
      "2018-05-31 05:50:17.069303 step\n",
      "2018-05-31 05:50:19.003307 Start validation\n",
      "2018-05-31 05:50:20.493524 Validation Accuracy = 0.8474\n",
      "2018-05-31 05:50:20.493665 Saving checkpoint of model...\n",
      "2018-05-31 05:50:20.724945 Model checkpoint saved at /checkpoints/model_epoch9.ckpt\n",
      "2018-05-31 05:50:20.725535 Epoch number: 10\n",
      "2018-05-31 05:50:24.212023 step\n",
      "2018-05-31 05:50:27.949278 step\n",
      "2018-05-31 05:50:31.716752 step\n",
      "2018-05-31 05:50:33.642106 Start validation\n",
      "2018-05-31 05:50:35.117781 Validation Accuracy = 0.7416\n",
      "2018-05-31 05:50:35.117912 Saving checkpoint of model...\n",
      "2018-05-31 05:50:35.361202 Model checkpoint saved at /checkpoints/model_epoch10.ckpt\n",
      "2018-05-31 05:50:35.361435 Epoch number: 11\n",
      "2018-05-31 05:50:38.800118 step\n",
      "2018-05-31 05:50:42.560919 step\n",
      "2018-05-31 05:50:46.313599 step\n",
      "2018-05-31 05:50:48.229068 Start validation\n",
      "2018-05-31 05:50:49.711377 Validation Accuracy = 0.7728\n",
      "2018-05-31 05:50:49.711513 Saving checkpoint of model...\n",
      "2018-05-31 05:50:49.942211 Model checkpoint saved at /checkpoints/model_epoch11.ckpt\n",
      "2018-05-31 05:50:49.942399 Epoch number: 12\n",
      "2018-05-31 05:50:53.364817 step\n",
      "2018-05-31 05:50:57.069506 step\n",
      "2018-05-31 05:51:00.865920 step\n",
      "2018-05-31 05:51:02.771924 Start validation\n",
      "2018-05-31 05:51:04.255316 Validation Accuracy = 0.7512\n",
      "2018-05-31 05:51:04.255457 Saving checkpoint of model...\n",
      "2018-05-31 05:51:04.512265 Model checkpoint saved at /checkpoints/model_epoch12.ckpt\n",
      "2018-05-31 05:51:04.512488 Epoch number: 13\n",
      "2018-05-31 05:51:07.941288 step\n",
      "2018-05-31 05:51:11.568898 step\n",
      "2018-05-31 05:51:15.294396 step\n",
      "2018-05-31 05:51:17.205154 Start validation\n",
      "2018-05-31 05:51:18.715931 Validation Accuracy = 0.7656\n",
      "2018-05-31 05:51:18.716351 Saving checkpoint of model...\n",
      "2018-05-31 05:51:18.968055 Model checkpoint saved at /checkpoints/model_epoch13.ckpt\n",
      "2018-05-31 05:51:18.968528 Epoch number: 14\n",
      "2018-05-31 05:51:22.432838 step\n",
      "2018-05-31 05:51:26.113835 step\n",
      "2018-05-31 05:51:29.865114 step\n",
      "2018-05-31 05:51:31.802390 Start validation\n",
      "2018-05-31 05:51:33.286709 Validation Accuracy = 0.7620\n",
      "2018-05-31 05:51:33.286829 Saving checkpoint of model...\n",
      "2018-05-31 05:51:33.576618 Model checkpoint saved at /checkpoints/model_epoch14.ckpt\n",
      "2018-05-31 05:51:33.577116 Epoch number: 15\n",
      "2018-05-31 05:51:37.008799 step\n",
      "2018-05-31 05:51:40.748216 step\n",
      "2018-05-31 05:51:44.522262 step\n",
      "2018-05-31 05:51:46.469695 Start validation\n",
      "2018-05-31 05:51:47.964854 Validation Accuracy = 0.7043\n",
      "2018-05-31 05:51:47.964970 Saving checkpoint of model...\n",
      "2018-05-31 05:51:48.219357 Model checkpoint saved at /checkpoints/model_epoch15.ckpt\n",
      "2018-05-31 05:51:48.219550 Epoch number: 16\n",
      "2018-05-31 05:51:51.621200 step\n",
      "2018-05-31 05:51:55.294992 step\n",
      "2018-05-31 05:51:59.050648 step\n",
      "2018-05-31 05:52:00.993060 Start validation\n",
      "2018-05-31 05:52:02.516067 Validation Accuracy = 0.7716\n",
      "2018-05-31 05:52:02.516245 Saving checkpoint of model...\n",
      "2018-05-31 05:52:02.765941 Model checkpoint saved at /checkpoints/model_epoch16.ckpt\n",
      "2018-05-31 05:52:02.766133 Epoch number: 17\n",
      "2018-05-31 05:52:06.284581 step\n",
      "2018-05-31 05:52:09.984918 step\n",
      "2018-05-31 05:52:13.700607 step\n",
      "2018-05-31 05:52:15.640001 Start validation\n",
      "2018-05-31 05:52:17.107612 Validation Accuracy = 0.7933\n",
      "2018-05-31 05:52:17.107742 Saving checkpoint of model...\n",
      "2018-05-31 05:52:17.355149 Model checkpoint saved at /checkpoints/model_epoch17.ckpt\n",
      "2018-05-31 05:52:17.355337 Epoch number: 18\n",
      "2018-05-31 05:52:20.854550 step\n",
      "2018-05-31 05:52:24.485857 step\n",
      "2018-05-31 05:52:28.266893 step\n",
      "2018-05-31 05:52:30.235511 Start validation\n",
      "2018-05-31 05:52:31.723429 Validation Accuracy = 0.7404\n",
      "2018-05-31 05:52:31.723560 Saving checkpoint of model...\n",
      "2018-05-31 05:52:31.967126 Model checkpoint saved at /checkpoints/model_epoch18.ckpt\n",
      "2018-05-31 05:52:31.967351 Epoch number: 19\n",
      "2018-05-31 05:52:35.384909 step\n",
      "2018-05-31 05:52:39.059960 step\n",
      "2018-05-31 05:52:42.803404 step\n",
      "2018-05-31 05:52:44.723225 Start validation\n",
      "2018-05-31 05:52:46.183650 Validation Accuracy = 0.8029\n",
      "2018-05-31 05:52:46.183787 Saving checkpoint of model...\n",
      "2018-05-31 05:52:46.424184 Model checkpoint saved at /checkpoints/model_epoch19.ckpt\n",
      "2018-05-31 05:52:46.424377 Epoch number: 20\n",
      "2018-05-31 05:52:49.820671 step\n",
      "2018-05-31 05:52:53.488320 step\n",
      "2018-05-31 05:52:57.274010 step\n",
      "2018-05-31 05:52:59.225567 Start validation\n",
      "2018-05-31 05:53:00.710338 Validation Accuracy = 0.6947\n",
      "2018-05-31 05:53:00.710474 Saving checkpoint of model...\n",
      "2018-05-31 05:53:00.947523 Model checkpoint saved at /checkpoints/model_epoch20.ckpt\n",
      "2018-05-31 05:53:00.948044 Epoch number: 21\n",
      "2018-05-31 05:53:04.372155 step\n",
      "2018-05-31 05:53:08.256549 step\n",
      "2018-05-31 05:53:12.081502 step\n",
      "2018-05-31 05:53:14.015484 Start validation\n",
      "2018-05-31 05:53:15.499277 Validation Accuracy = 0.7861\n",
      "2018-05-31 05:53:15.499388 Saving checkpoint of model...\n",
      "2018-05-31 05:53:15.735855 Model checkpoint saved at /checkpoints/model_epoch21.ckpt\n",
      "2018-05-31 05:53:15.736045 Epoch number: 22\n",
      "2018-05-31 05:53:19.259534 step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:53:23.041367 step\n",
      "2018-05-31 05:53:27.048659 step\n",
      "2018-05-31 05:53:28.975635 Start validation\n",
      "2018-05-31 05:53:30.477671 Validation Accuracy = 0.7608\n",
      "2018-05-31 05:53:30.478034 Saving checkpoint of model...\n",
      "2018-05-31 05:53:30.712491 Model checkpoint saved at /checkpoints/model_epoch22.ckpt\n",
      "2018-05-31 05:53:30.712674 Epoch number: 23\n",
      "2018-05-31 05:53:34.178630 step\n",
      "2018-05-31 05:53:37.929887 step\n",
      "2018-05-31 05:53:41.729756 step\n",
      "2018-05-31 05:53:43.721616 Start validation\n",
      "2018-05-31 05:53:45.307202 Validation Accuracy = 0.7812\n",
      "2018-05-31 05:53:45.307401 Saving checkpoint of model...\n",
      "2018-05-31 05:53:45.559699 Model checkpoint saved at /checkpoints/model_epoch23.ckpt\n",
      "2018-05-31 05:53:45.559891 Epoch number: 24\n",
      "2018-05-31 05:53:49.024154 step\n",
      "2018-05-31 05:53:52.737123 step\n",
      "2018-05-31 05:53:56.551398 step\n",
      "2018-05-31 05:53:58.631844 Start validation\n",
      "2018-05-31 05:54:00.141192 Validation Accuracy = 0.8041\n",
      "2018-05-31 05:54:00.141312 Saving checkpoint of model...\n",
      "2018-05-31 05:54:00.371302 Model checkpoint saved at /checkpoints/model_epoch24.ckpt\n",
      "2018-05-31 05:54:00.371490 Epoch number: 25\n",
      "2018-05-31 05:54:03.727552 step\n",
      "2018-05-31 05:54:07.469886 step\n",
      "2018-05-31 05:54:11.232188 step\n",
      "2018-05-31 05:54:13.149771 Start validation\n",
      "2018-05-31 05:54:14.630102 Validation Accuracy = 0.7704\n",
      "2018-05-31 05:54:14.630210 Saving checkpoint of model...\n",
      "2018-05-31 05:54:14.878080 Model checkpoint saved at /checkpoints/model_epoch25.ckpt\n",
      "2018-05-31 05:54:14.878300 Epoch number: 26\n",
      "2018-05-31 05:54:18.283719 step\n",
      "2018-05-31 05:54:21.985901 step\n",
      "2018-05-31 05:54:25.758682 step\n",
      "2018-05-31 05:54:27.703308 Start validation\n",
      "2018-05-31 05:54:29.182392 Validation Accuracy = 0.7825\n",
      "2018-05-31 05:54:29.182521 Saving checkpoint of model...\n",
      "2018-05-31 05:54:29.621082 Model checkpoint saved at /checkpoints/model_epoch26.ckpt\n",
      "2018-05-31 05:54:29.621277 Epoch number: 27\n",
      "2018-05-31 05:54:33.030695 step\n",
      "2018-05-31 05:54:36.803679 step\n",
      "2018-05-31 05:54:40.536725 step\n",
      "2018-05-31 05:54:42.481479 Start validation\n",
      "2018-05-31 05:54:43.962793 Validation Accuracy = 0.7356\n",
      "2018-05-31 05:54:43.962928 Saving checkpoint of model...\n",
      "2018-05-31 05:54:44.410929 Model checkpoint saved at /checkpoints/model_epoch27.ckpt\n",
      "2018-05-31 05:54:44.411126 Epoch number: 28\n",
      "2018-05-31 05:54:47.820419 step\n",
      "2018-05-31 05:54:51.648123 step\n",
      "2018-05-31 05:54:55.442493 step\n",
      "2018-05-31 05:54:57.415850 Start validation\n",
      "2018-05-31 05:54:58.937706 Validation Accuracy = 0.7620\n",
      "2018-05-31 05:54:58.937841 Saving checkpoint of model...\n",
      "2018-05-31 05:54:59.355269 Model checkpoint saved at /checkpoints/model_epoch28.ckpt\n",
      "2018-05-31 05:54:59.355680 Epoch number: 29\n",
      "2018-05-31 05:55:02.747381 step\n",
      "2018-05-31 05:55:06.407965 step\n",
      "2018-05-31 05:55:10.135307 step\n",
      "2018-05-31 05:55:12.093937 Start validation\n",
      "2018-05-31 05:55:13.605378 Validation Accuracy = 0.8065\n",
      "2018-05-31 05:55:13.605511 Saving checkpoint of model...\n",
      "2018-05-31 05:55:14.000917 Model checkpoint saved at /checkpoints/model_epoch29.ckpt\n",
      "2018-05-31 05:55:14.001133 Epoch number: 30\n",
      "2018-05-31 05:55:17.421446 step\n",
      "2018-05-31 05:55:21.224858 step\n",
      "2018-05-31 05:55:25.002254 step\n",
      "2018-05-31 05:55:26.960220 Start validation\n",
      "2018-05-31 05:55:28.458965 Validation Accuracy = 0.7704\n",
      "2018-05-31 05:55:28.459071 Saving checkpoint of model...\n",
      "2018-05-31 05:55:28.883297 Model checkpoint saved at /checkpoints/model_epoch30.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Start Tensorflow session\n",
    "config=tf.ConfigProto(allow_soft_placement = True)\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # Load the pretrained weights into the non-trainable layer\n",
    "    model.load_initial_weights(sess)\n",
    "\n",
    "    print(\"{} Start training...\".format(datetime.now()))\n",
    "    print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(),\n",
    "                                                      filewriter_path))\n",
    "\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(\"{} Epoch number: {}\".format(datetime.now(), epoch+1))\n",
    "\n",
    "        # Initialize iterator with the training dataset\n",
    "        sess.run(training_init_op)\n",
    "\n",
    "        for step in range(train_batches_per_epoch):\n",
    "\n",
    "            # get next batch of data\n",
    "            img_batch, label_batch = sess.run(next_batch)       \n",
    "\n",
    "            # And run the training op\n",
    "            sess.run(train_op, feed_dict={x: img_batch,\n",
    "                                          y: label_batch,\n",
    "                                          keep_prob: dropout_rate})\n",
    "\n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            if step % display_step == 0:\n",
    "                s = sess.run(merged_summary, feed_dict={x: img_batch,\n",
    "                                                        y: label_batch,\n",
    "                                                        keep_prob: 1.})\n",
    "                writer.add_summary(s, epoch*train_batches_per_epoch + step)\n",
    "                print(\"{} step\".format(datetime.now(), step))\n",
    "\n",
    "        # Validate the model on the entire validation set\n",
    "        print(\"{} Start validation\".format(datetime.now()))\n",
    "        sess.run(validation_init_op)\n",
    "        test_acc = 0.\n",
    "        test_count = 0\n",
    "        for _ in range(val_batches_per_epoch):\n",
    "\n",
    "            img_batch, label_batch = sess.run(next_batch)\n",
    "            acc = sess.run(accuracy, feed_dict={x: img_batch,\n",
    "                                                y: label_batch,\n",
    "                                                keep_prob: 1.})\n",
    "            test_acc += acc\n",
    "            test_count += 1\n",
    "        test_acc /= test_count\n",
    "        print(\"{} Validation Accuracy = {:.4f}\".format(datetime.now(),\n",
    "                                                       test_acc))\n",
    "        print(\"{} Saving checkpoint of model...\".format(datetime.now()))\n",
    "\n",
    "        # save checkpoint of the model\n",
    "        checkpoint_name = os.path.join(checkpoint_path,\n",
    "                                       'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "        save_path = saver.save(sess, checkpoint_name)\n",
    "\n",
    "        print(\"{} Model checkpoint saved at {}\".format(datetime.now(),\n",
    "                                                       checkpoint_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
