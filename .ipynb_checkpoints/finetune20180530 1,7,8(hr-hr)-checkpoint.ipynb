{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nConfiguration Part.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Script to finetune AlexNet using Tensorflow.\n",
    "\n",
    "With this script you can finetune AlexNet as provided in the alexnet.py\n",
    "class on any given dataset. Specify the configuration settings at the\n",
    "beginning according to your problem.\n",
    "This script was written for TensorFlow >= version 1.2rc0 and comes with a blog\n",
    "post, which you can find here:\n",
    "\n",
    "https://kratzert.github.io/2017/02/24/finetuning-alexnet-with-tensorflow.html\n",
    "\n",
    "Author: Frederik Kratzert\n",
    "contact: f.kratzert(at)gmail.com\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "\n",
    "from alexnet import AlexNet\n",
    "from datagenerator import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "from tensorflow.contrib.data import Iterator\n",
    "\n",
    "\"\"\"\n",
    "Configuration Part.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the textfiles for the trainings and validation set\n",
    "train_file = './trainhr.txt'\n",
    "val_file = './testhr.txt'\n",
    "\n",
    "# Learning params\n",
    "learning_rate = 0.02\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Network params\n",
    "dropout_rate = 0.5\n",
    "num_classes = 2\n",
    "train_layers = ['fc8','fc7','conv1']\n",
    "\n",
    "# How often we want to write the tf.summary data to disk\n",
    "display_step = 20\n",
    "\n",
    "# Path for tf.summary.FileWriter and to store model checkpoints\n",
    "filewriter_path = \"/tensorboard\"\n",
    "checkpoint_path = \"/checkpoints\"\n",
    "\n",
    "\"\"\"\n",
    "Main Part of the finetuning Script.\n",
    "\"\"\"\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)\n",
    "\n",
    "# Place data loading and preprocessing on the cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /temp/datagenerator.py:66: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with output_buffer_size is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with num_threads is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    tr_data = ImageDataGenerator(train_file,\n",
    "                                 mode='training',\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_classes=num_classes,\n",
    "                                 shuffle=True)\n",
    "    val_data = ImageDataGenerator(val_file,\n",
    "                                  mode='inference',\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_classes=num_classes,\n",
    "                                  shuffle=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an reinitializable iterator given the dataset structure\n",
    "iterator = Iterator.from_structure(tr_data.data.output_types,\n",
    "                                       tr_data.data.output_shapes)\n",
    "\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Ops for initializing the two different iterators\n",
    "training_init_op = iterator.make_initializer(tr_data.data)\n",
    "validation_init_op = iterator.make_initializer(val_data.data)\n",
    "\n",
    "# TF placeholder for graph input and output\n",
    "x = tf.placeholder(tf.float32, [batch_size, 227, 227, 3])\n",
    "y = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AlexNet(x, keep_prob, num_classes, train_layers)\n",
    "\n",
    "# Link variable to model output\n",
    "score = model.fc8\n",
    "\n",
    "# List of trainable variables of the layers we want to train\n",
    "var_list = [v for v in tf.trainable_variables() if v.name.split('/')[0] in train_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-ae74111bad46>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Summary name conv1/weights:0/gradient is illegal; using conv1/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0/gradient is illegal; using conv1/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/weights:0/gradient is illegal; using fc7/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0/gradient is illegal; using fc7/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0/gradient is illegal; using fc8/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0/gradient is illegal; using fc8/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/weights:0 is illegal; using conv1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0 is illegal; using conv1/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc7/weights:0 is illegal; using fc7/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0 is illegal; using fc7/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0 is illegal; using fc8/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0 is illegal; using fc8/biases_0 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Op for calculating the loss\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=score,\n",
    "                                                                  labels=y))\n",
    "\n",
    "# Train op\n",
    "with tf.name_scope(\"train\"):\n",
    "    # Get gradients of all trainable variables\n",
    "    gradients = tf.gradients(loss, var_list)\n",
    "    gradients = list(zip(gradients, var_list))\n",
    "\n",
    "    # Create optimizer and apply gradient descent to the trainable variables\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "\n",
    "# Add gradients to summary\n",
    "for gradient, var in gradients:\n",
    "    tf.summary.histogram(var.name + '/gradient', gradient)\n",
    "\n",
    "# Add the variables we train to the summary\n",
    "for var in var_list:\n",
    "    tf.summary.histogram(var.name, var)\n",
    "\n",
    "# Add the loss to summary\n",
    "tf.summary.scalar('cross_entropy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation op: Accuracy of the model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(score, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Add the accuracy to the summary\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(filewriter_path)\n",
    "\n",
    "# Initialize an saver for store model checkpoints\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Get the number of training/validation steps per epoch\n",
    "train_batches_per_epoch = int(np.floor(tr_data.data_size/batch_size))\n",
    "val_batches_per_epoch = int(np.floor(val_data.data_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:41:26.583081 Start training...\n",
      "2018-05-31 05:41:26.583207 Open Tensorboard at --logdir /tensorboard\n",
      "2018-05-31 05:41:26.583246 Epoch number: 1\n",
      "2018-05-31 05:41:30.651652 step\n",
      "2018-05-31 05:41:33.595197 step\n",
      "2018-05-31 05:41:36.583414 step\n",
      "2018-05-31 05:41:38.460781 Start validation\n",
      "2018-05-31 05:41:40.053212 Validation Accuracy = 0.5156\n",
      "2018-05-31 05:41:40.053327 Saving checkpoint of model...\n",
      "2018-05-31 05:41:40.607708 Model checkpoint saved at /checkpoints/model_epoch1.ckpt\n",
      "2018-05-31 05:41:40.607810 Epoch number: 2\n",
      "2018-05-31 05:41:43.042102 step\n",
      "2018-05-31 05:41:46.063310 step\n",
      "2018-05-31 05:41:49.070990 step\n",
      "2018-05-31 05:41:50.961935 Start validation\n",
      "2018-05-31 05:41:52.451481 Validation Accuracy = 0.6611\n",
      "2018-05-31 05:41:52.451588 Saving checkpoint of model...\n",
      "2018-05-31 05:41:52.860302 Model checkpoint saved at /checkpoints/model_epoch2.ckpt\n",
      "2018-05-31 05:41:52.860494 Epoch number: 3\n",
      "2018-05-31 05:41:55.406576 step\n",
      "2018-05-31 05:41:58.523380 step\n",
      "2018-05-31 05:42:01.517514 step\n",
      "2018-05-31 05:42:03.391082 Start validation\n",
      "2018-05-31 05:42:04.868503 Validation Accuracy = 0.6322\n",
      "2018-05-31 05:42:04.868636 Saving checkpoint of model...\n",
      "2018-05-31 05:42:05.296659 Model checkpoint saved at /checkpoints/model_epoch3.ckpt\n",
      "2018-05-31 05:42:05.296876 Epoch number: 4\n",
      "2018-05-31 05:42:07.778871 step\n",
      "2018-05-31 05:42:10.934261 step\n",
      "2018-05-31 05:42:13.931145 step\n",
      "2018-05-31 05:42:15.834383 Start validation\n",
      "2018-05-31 05:42:17.332673 Validation Accuracy = 0.6899\n",
      "2018-05-31 05:42:17.332787 Saving checkpoint of model...\n",
      "2018-05-31 05:42:17.736915 Model checkpoint saved at /checkpoints/model_epoch4.ckpt\n",
      "2018-05-31 05:42:17.737040 Epoch number: 5\n",
      "2018-05-31 05:42:20.189814 step\n",
      "2018-05-31 05:42:23.282070 step\n",
      "2018-05-31 05:42:26.270200 step\n",
      "2018-05-31 05:42:28.167131 Start validation\n",
      "2018-05-31 05:42:29.655826 Validation Accuracy = 0.6707\n",
      "2018-05-31 05:42:29.655954 Saving checkpoint of model...\n",
      "2018-05-31 05:42:30.075397 Model checkpoint saved at /checkpoints/model_epoch5.ckpt\n",
      "2018-05-31 05:42:30.075503 Epoch number: 6\n",
      "2018-05-31 05:42:32.494768 step\n",
      "2018-05-31 05:42:35.516419 step\n",
      "2018-05-31 05:42:38.519192 step\n",
      "2018-05-31 05:42:40.425142 Start validation\n",
      "2018-05-31 05:42:41.905168 Validation Accuracy = 0.7332\n",
      "2018-05-31 05:42:41.905282 Saving checkpoint of model...\n",
      "2018-05-31 05:42:42.356506 Model checkpoint saved at /checkpoints/model_epoch6.ckpt\n",
      "2018-05-31 05:42:42.356610 Epoch number: 7\n",
      "2018-05-31 05:42:44.859995 step\n",
      "2018-05-31 05:42:47.939299 step\n",
      "2018-05-31 05:42:50.897608 step\n",
      "2018-05-31 05:42:52.780505 Start validation\n",
      "2018-05-31 05:42:54.259358 Validation Accuracy = 0.7524\n",
      "2018-05-31 05:42:54.259478 Saving checkpoint of model...\n",
      "2018-05-31 05:42:54.709029 Model checkpoint saved at /checkpoints/model_epoch7.ckpt\n",
      "2018-05-31 05:42:54.709132 Epoch number: 8\n",
      "2018-05-31 05:42:57.126652 step\n",
      "2018-05-31 05:43:00.195553 step\n",
      "2018-05-31 05:43:03.145992 step\n",
      "2018-05-31 05:43:05.051017 Start validation\n",
      "2018-05-31 05:43:06.518441 Validation Accuracy = 0.6815\n",
      "2018-05-31 05:43:06.518547 Saving checkpoint of model...\n",
      "2018-05-31 05:43:06.972331 Model checkpoint saved at /checkpoints/model_epoch8.ckpt\n",
      "2018-05-31 05:43:06.972435 Epoch number: 9\n",
      "2018-05-31 05:43:09.461105 step\n",
      "2018-05-31 05:43:12.520092 step\n",
      "2018-05-31 05:43:15.504953 step\n",
      "2018-05-31 05:43:17.421210 Start validation\n",
      "2018-05-31 05:43:18.906542 Validation Accuracy = 0.6587\n",
      "2018-05-31 05:43:18.906669 Saving checkpoint of model...\n",
      "2018-05-31 05:43:19.366012 Model checkpoint saved at /checkpoints/model_epoch9.ckpt\n",
      "2018-05-31 05:43:19.366120 Epoch number: 10\n",
      "2018-05-31 05:43:21.828386 step\n",
      "2018-05-31 05:43:24.874078 step\n",
      "2018-05-31 05:43:27.932547 step\n",
      "2018-05-31 05:43:29.829586 Start validation\n",
      "2018-05-31 05:43:31.297330 Validation Accuracy = 0.7139\n",
      "2018-05-31 05:43:31.297442 Saving checkpoint of model...\n",
      "2018-05-31 05:43:31.739206 Model checkpoint saved at /checkpoints/model_epoch10.ckpt\n",
      "2018-05-31 05:43:31.739307 Epoch number: 11\n",
      "2018-05-31 05:43:34.180509 step\n",
      "2018-05-31 05:43:37.263898 step\n",
      "2018-05-31 05:43:40.241812 step\n",
      "2018-05-31 05:43:42.134384 Start validation\n",
      "2018-05-31 05:43:43.593138 Validation Accuracy = 0.6947\n",
      "2018-05-31 05:43:43.593249 Saving checkpoint of model...\n",
      "2018-05-31 05:43:44.062724 Model checkpoint saved at /checkpoints/model_epoch11.ckpt\n",
      "2018-05-31 05:43:44.062835 Epoch number: 12\n",
      "2018-05-31 05:43:46.500603 step\n",
      "2018-05-31 05:43:49.536210 step\n",
      "2018-05-31 05:43:52.519463 step\n",
      "2018-05-31 05:43:54.416081 Start validation\n",
      "2018-05-31 05:43:55.957267 Validation Accuracy = 0.5625\n",
      "2018-05-31 05:43:55.957392 Saving checkpoint of model...\n",
      "2018-05-31 05:43:56.414296 Model checkpoint saved at /checkpoints/model_epoch12.ckpt\n",
      "2018-05-31 05:43:56.414398 Epoch number: 13\n",
      "2018-05-31 05:43:58.857683 step\n",
      "2018-05-31 05:44:01.910741 step\n",
      "2018-05-31 05:44:04.866989 step\n",
      "2018-05-31 05:44:06.777961 Start validation\n",
      "2018-05-31 05:44:08.263797 Validation Accuracy = 0.6755\n",
      "2018-05-31 05:44:08.263909 Saving checkpoint of model...\n",
      "2018-05-31 05:44:08.725242 Model checkpoint saved at /checkpoints/model_epoch13.ckpt\n",
      "2018-05-31 05:44:08.725348 Epoch number: 14\n",
      "2018-05-31 05:44:11.169492 step\n",
      "2018-05-31 05:44:14.238355 step\n",
      "2018-05-31 05:44:17.279761 step\n",
      "2018-05-31 05:44:19.177490 Start validation\n",
      "2018-05-31 05:44:20.655488 Validation Accuracy = 0.7127\n",
      "2018-05-31 05:44:20.655606 Saving checkpoint of model...\n",
      "2018-05-31 05:44:21.175879 Model checkpoint saved at /checkpoints/model_epoch14.ckpt\n",
      "2018-05-31 05:44:21.175978 Epoch number: 15\n",
      "2018-05-31 05:44:23.720472 step\n",
      "2018-05-31 05:44:26.861584 step\n",
      "2018-05-31 05:44:29.818391 step\n",
      "2018-05-31 05:44:31.704385 Start validation\n",
      "2018-05-31 05:44:33.165132 Validation Accuracy = 0.7163\n",
      "2018-05-31 05:44:33.165260 Saving checkpoint of model...\n",
      "2018-05-31 05:44:33.628544 Model checkpoint saved at /checkpoints/model_epoch15.ckpt\n",
      "2018-05-31 05:44:33.628646 Epoch number: 16\n",
      "2018-05-31 05:44:36.070220 step\n",
      "2018-05-31 05:44:39.216317 step\n",
      "2018-05-31 05:44:42.228122 step\n",
      "2018-05-31 05:44:44.106173 Start validation\n",
      "2018-05-31 05:44:45.565377 Validation Accuracy = 0.7332\n",
      "2018-05-31 05:44:45.565485 Saving checkpoint of model...\n",
      "2018-05-31 05:44:46.034360 Model checkpoint saved at /checkpoints/model_epoch16.ckpt\n",
      "2018-05-31 05:44:46.034608 Epoch number: 17\n",
      "2018-05-31 05:44:48.514589 step\n",
      "2018-05-31 05:44:51.592660 step\n",
      "2018-05-31 05:44:54.580999 step\n",
      "2018-05-31 05:44:56.467782 Start validation\n",
      "2018-05-31 05:44:57.957305 Validation Accuracy = 0.6935\n",
      "2018-05-31 05:44:57.957414 Saving checkpoint of model...\n",
      "2018-05-31 05:44:58.437903 Model checkpoint saved at /checkpoints/model_epoch17.ckpt\n",
      "2018-05-31 05:44:58.438008 Epoch number: 18\n",
      "2018-05-31 05:45:00.884554 step\n",
      "2018-05-31 05:45:03.890719 step\n",
      "2018-05-31 05:45:06.892974 step\n",
      "2018-05-31 05:45:08.812869 Start validation\n",
      "2018-05-31 05:45:10.308023 Validation Accuracy = 0.7512\n",
      "2018-05-31 05:45:10.308158 Saving checkpoint of model...\n",
      "2018-05-31 05:45:10.760202 Model checkpoint saved at /checkpoints/model_epoch18.ckpt\n",
      "2018-05-31 05:45:10.760491 Epoch number: 19\n",
      "2018-05-31 05:45:13.246179 step\n",
      "2018-05-31 05:45:16.327071 step\n",
      "2018-05-31 05:45:19.311448 step\n",
      "2018-05-31 05:45:21.196354 Start validation\n",
      "2018-05-31 05:45:22.692173 Validation Accuracy = 0.7476\n",
      "2018-05-31 05:45:22.692301 Saving checkpoint of model...\n",
      "2018-05-31 05:45:23.146186 Model checkpoint saved at /checkpoints/model_epoch19.ckpt\n",
      "2018-05-31 05:45:23.146294 Epoch number: 20\n",
      "2018-05-31 05:45:25.565900 step\n",
      "2018-05-31 05:45:28.688745 step\n",
      "2018-05-31 05:45:31.649307 step\n",
      "2018-05-31 05:45:33.560149 Start validation\n",
      "2018-05-31 05:45:35.035356 Validation Accuracy = 0.7885\n",
      "2018-05-31 05:45:35.035486 Saving checkpoint of model...\n",
      "2018-05-31 05:45:35.495545 Model checkpoint saved at /checkpoints/model_epoch20.ckpt\n",
      "2018-05-31 05:45:35.495645 Epoch number: 21\n",
      "2018-05-31 05:45:37.926653 step\n",
      "2018-05-31 05:45:41.095682 step\n",
      "2018-05-31 05:45:44.066746 step\n",
      "2018-05-31 05:45:45.951682 Start validation\n",
      "2018-05-31 05:45:47.423452 Validation Accuracy = 0.7644\n",
      "2018-05-31 05:45:47.423591 Saving checkpoint of model...\n",
      "2018-05-31 05:45:47.874466 Model checkpoint saved at /checkpoints/model_epoch21.ckpt\n",
      "2018-05-31 05:45:47.874575 Epoch number: 22\n",
      "2018-05-31 05:45:50.346019 step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:45:53.448495 step\n",
      "2018-05-31 05:45:56.438506 step\n",
      "2018-05-31 05:45:58.367778 Start validation\n",
      "2018-05-31 05:45:59.889855 Validation Accuracy = 0.7885\n",
      "2018-05-31 05:45:59.890044 Saving checkpoint of model...\n",
      "2018-05-31 05:46:00.359305 Model checkpoint saved at /checkpoints/model_epoch22.ckpt\n",
      "2018-05-31 05:46:00.359412 Epoch number: 23\n",
      "2018-05-31 05:46:02.867844 step\n",
      "2018-05-31 05:46:06.125687 step\n",
      "2018-05-31 05:46:09.080788 step\n",
      "2018-05-31 05:46:10.977297 Start validation\n",
      "2018-05-31 05:46:12.481817 Validation Accuracy = 0.7620\n",
      "2018-05-31 05:46:12.481954 Saving checkpoint of model...\n",
      "2018-05-31 05:46:12.953219 Model checkpoint saved at /checkpoints/model_epoch23.ckpt\n",
      "2018-05-31 05:46:12.953345 Epoch number: 24\n",
      "2018-05-31 05:46:15.538429 step\n",
      "2018-05-31 05:46:18.759424 step\n",
      "2018-05-31 05:46:21.720386 step\n",
      "2018-05-31 05:46:23.609303 Start validation\n",
      "2018-05-31 05:46:25.096061 Validation Accuracy = 0.7079\n",
      "2018-05-31 05:46:25.096182 Saving checkpoint of model...\n",
      "2018-05-31 05:46:25.569266 Model checkpoint saved at /checkpoints/model_epoch24.ckpt\n",
      "2018-05-31 05:46:25.569397 Epoch number: 25\n",
      "2018-05-31 05:46:28.021731 step\n",
      "2018-05-31 05:46:31.217093 step\n",
      "2018-05-31 05:46:34.174401 step\n",
      "2018-05-31 05:46:36.124088 Start validation\n",
      "2018-05-31 05:46:37.637131 Validation Accuracy = 0.7536\n",
      "2018-05-31 05:46:37.637252 Saving checkpoint of model...\n",
      "2018-05-31 05:46:38.127192 Model checkpoint saved at /checkpoints/model_epoch25.ckpt\n",
      "2018-05-31 05:46:38.127297 Epoch number: 26\n",
      "2018-05-31 05:46:40.658402 step\n",
      "2018-05-31 05:46:43.802675 step\n",
      "2018-05-31 05:46:46.800109 step\n",
      "2018-05-31 05:46:48.709129 Start validation\n",
      "2018-05-31 05:46:50.218739 Validation Accuracy = 0.7764\n",
      "2018-05-31 05:46:50.218872 Saving checkpoint of model...\n",
      "2018-05-31 05:46:50.934854 Model checkpoint saved at /checkpoints/model_epoch26.ckpt\n",
      "2018-05-31 05:46:50.934967 Epoch number: 27\n",
      "2018-05-31 05:46:53.496090 step\n",
      "2018-05-31 05:46:56.625774 step\n",
      "2018-05-31 05:46:59.594188 step\n",
      "2018-05-31 05:47:01.501748 Start validation\n",
      "2018-05-31 05:47:03.068698 Validation Accuracy = 0.7692\n",
      "2018-05-31 05:47:03.068875 Saving checkpoint of model...\n",
      "2018-05-31 05:47:03.840010 Model checkpoint saved at /checkpoints/model_epoch27.ckpt\n",
      "2018-05-31 05:47:03.840135 Epoch number: 28\n",
      "2018-05-31 05:47:06.343658 step\n",
      "2018-05-31 05:47:09.488878 step\n",
      "2018-05-31 05:47:12.618450 step\n",
      "2018-05-31 05:47:14.679740 Start validation\n",
      "2018-05-31 05:47:16.215825 Validation Accuracy = 0.7404\n",
      "2018-05-31 05:47:16.215955 Saving checkpoint of model...\n",
      "2018-05-31 05:47:16.998775 Model checkpoint saved at /checkpoints/model_epoch28.ckpt\n",
      "2018-05-31 05:47:16.998911 Epoch number: 29\n",
      "2018-05-31 05:47:19.564649 step\n",
      "2018-05-31 05:47:22.590221 step\n",
      "2018-05-31 05:47:25.594541 step\n",
      "2018-05-31 05:47:27.496246 Start validation\n",
      "2018-05-31 05:47:29.070288 Validation Accuracy = 0.7740\n",
      "2018-05-31 05:47:29.070405 Saving checkpoint of model...\n",
      "2018-05-31 05:47:29.853209 Model checkpoint saved at /checkpoints/model_epoch29.ckpt\n",
      "2018-05-31 05:47:29.853316 Epoch number: 30\n",
      "2018-05-31 05:47:32.344782 step\n",
      "2018-05-31 05:47:35.452022 step\n",
      "2018-05-31 05:47:38.418272 step\n",
      "2018-05-31 05:47:40.347080 Start validation\n",
      "2018-05-31 05:47:41.835949 Validation Accuracy = 0.7392\n",
      "2018-05-31 05:47:41.836081 Saving checkpoint of model...\n",
      "2018-05-31 05:47:42.615904 Model checkpoint saved at /checkpoints/model_epoch30.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Start Tensorflow session\n",
    "config=tf.ConfigProto(allow_soft_placement = True)\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # Load the pretrained weights into the non-trainable layer\n",
    "    model.load_initial_weights(sess)\n",
    "\n",
    "    print(\"{} Start training...\".format(datetime.now()))\n",
    "    print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(),\n",
    "                                                      filewriter_path))\n",
    "\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(\"{} Epoch number: {}\".format(datetime.now(), epoch+1))\n",
    "\n",
    "        # Initialize iterator with the training dataset\n",
    "        sess.run(training_init_op)\n",
    "\n",
    "        for step in range(train_batches_per_epoch):\n",
    "\n",
    "            # get next batch of data\n",
    "            img_batch, label_batch = sess.run(next_batch)       \n",
    "\n",
    "            # And run the training op\n",
    "            sess.run(train_op, feed_dict={x: img_batch,\n",
    "                                          y: label_batch,\n",
    "                                          keep_prob: dropout_rate})\n",
    "\n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            if step % display_step == 0:\n",
    "                s = sess.run(merged_summary, feed_dict={x: img_batch,\n",
    "                                                        y: label_batch,\n",
    "                                                        keep_prob: 1.})\n",
    "                writer.add_summary(s, epoch*train_batches_per_epoch + step)\n",
    "                print(\"{} step\".format(datetime.now(), step))\n",
    "\n",
    "        # Validate the model on the entire validation set\n",
    "        print(\"{} Start validation\".format(datetime.now()))\n",
    "        sess.run(validation_init_op)\n",
    "        test_acc = 0.\n",
    "        test_count = 0\n",
    "        for _ in range(val_batches_per_epoch):\n",
    "\n",
    "            img_batch, label_batch = sess.run(next_batch)\n",
    "            acc = sess.run(accuracy, feed_dict={x: img_batch,\n",
    "                                                y: label_batch,\n",
    "                                                keep_prob: 1.})\n",
    "            test_acc += acc\n",
    "            test_count += 1\n",
    "        test_acc /= test_count\n",
    "        print(\"{} Validation Accuracy = {:.4f}\".format(datetime.now(),\n",
    "                                                       test_acc))\n",
    "        print(\"{} Saving checkpoint of model...\".format(datetime.now()))\n",
    "\n",
    "        # save checkpoint of the model\n",
    "        checkpoint_name = os.path.join(checkpoint_path,\n",
    "                                       'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "        save_path = saver.save(sess, checkpoint_name)\n",
    "\n",
    "        print(\"{} Model checkpoint saved at {}\".format(datetime.now(),\n",
    "                                                       checkpoint_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
