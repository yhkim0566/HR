{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nConfiguration Part.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Script to finetune AlexNet using Tensorflow.\n",
    "\n",
    "With this script you can finetune AlexNet as provided in the alexnet.py\n",
    "class on any given dataset. Specify the configuration settings at the\n",
    "beginning according to your problem.\n",
    "This script was written for TensorFlow >= version 1.2rc0 and comes with a blog\n",
    "post, which you can find here:\n",
    "\n",
    "https://kratzert.github.io/2017/02/24/finetuning-alexnet-with-tensorflow.html\n",
    "\n",
    "Author: Frederik Kratzert\n",
    "contact: f.kratzert(at)gmail.com\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "\n",
    "from alexnet import AlexNet\n",
    "from datagenerator import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "from tensorflow.contrib.data import Iterator\n",
    "\n",
    "\"\"\"\n",
    "Configuration Part.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the textfiles for the trainings and validation set\n",
    "train_file = './train.txt'\n",
    "val_file = './testoh.txt'\n",
    "\n",
    "# Learning params\n",
    "learning_rate = 0.02\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Network params\n",
    "dropout_rate = 0.5\n",
    "num_classes = 2\n",
    "train_layers = ['fc8','fc7','fc6','conv1']\n",
    "\n",
    "# How often we want to write the tf.summary data to disk\n",
    "display_step = 20\n",
    "\n",
    "# Path for tf.summary.FileWriter and to store model checkpoints\n",
    "filewriter_path = \"/tensorboard\"\n",
    "checkpoint_path = \"/checkpoints\"\n",
    "\n",
    "\"\"\"\n",
    "Main Part of the finetuning Script.\n",
    "\"\"\"\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)\n",
    "\n",
    "# Place data loading and preprocessing on the cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /temp/datagenerator.py:66: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with output_buffer_size is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n",
      "WARNING:tensorflow:From /temp/datagenerator.py:71: calling Dataset.map (from tensorflow.contrib.data.python.ops.dataset_ops) with num_threads is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Replace `num_threads=T` with `num_parallel_calls=T`. Replace `output_buffer_size=N` with `ds.prefetch(N)` on the returned dataset.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    tr_data = ImageDataGenerator(train_file,\n",
    "                                 mode='training',\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_classes=num_classes,\n",
    "                                 shuffle=True)\n",
    "    val_data = ImageDataGenerator(val_file,\n",
    "                                  mode='inference',\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_classes=num_classes,\n",
    "                                  shuffle=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an reinitializable iterator given the dataset structure\n",
    "iterator = Iterator.from_structure(tr_data.data.output_types,\n",
    "                                       tr_data.data.output_shapes)\n",
    "\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Ops for initializing the two different iterators\n",
    "training_init_op = iterator.make_initializer(tr_data.data)\n",
    "validation_init_op = iterator.make_initializer(val_data.data)\n",
    "\n",
    "# TF placeholder for graph input and output\n",
    "x = tf.placeholder(tf.float32, [batch_size, 227, 227, 3])\n",
    "y = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AlexNet(x, keep_prob, num_classes, train_layers)\n",
    "\n",
    "# Link variable to model output\n",
    "score = model.fc8\n",
    "\n",
    "# List of trainable variables of the layers we want to train\n",
    "var_list = [v for v in tf.trainable_variables() if v.name.split('/')[0] in train_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-ae74111bad46>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Summary name conv1/weights:0/gradient is illegal; using conv1/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0/gradient is illegal; using conv1/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc6/weights:0/gradient is illegal; using fc6/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc6/biases:0/gradient is illegal; using fc6/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/weights:0/gradient is illegal; using fc7/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0/gradient is illegal; using fc7/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0/gradient is illegal; using fc8/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0/gradient is illegal; using fc8/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name conv1/weights:0 is illegal; using conv1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name conv1/biases:0 is illegal; using conv1/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc6/weights:0 is illegal; using fc6/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc6/biases:0 is illegal; using fc6/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc7/weights:0 is illegal; using fc7/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0 is illegal; using fc7/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0 is illegal; using fc8/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0 is illegal; using fc8/biases_0 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Op for calculating the loss\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=score,\n",
    "                                                                  labels=y))\n",
    "\n",
    "# Train op\n",
    "with tf.name_scope(\"train\"):\n",
    "    # Get gradients of all trainable variables\n",
    "    gradients = tf.gradients(loss, var_list)\n",
    "    gradients = list(zip(gradients, var_list))\n",
    "\n",
    "    # Create optimizer and apply gradient descent to the trainable variables\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "\n",
    "# Add gradients to summary\n",
    "for gradient, var in gradients:\n",
    "    tf.summary.histogram(var.name + '/gradient', gradient)\n",
    "\n",
    "# Add the variables we train to the summary\n",
    "for var in var_list:\n",
    "    tf.summary.histogram(var.name, var)\n",
    "\n",
    "# Add the loss to summary\n",
    "tf.summary.scalar('cross_entropy', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation op: Accuracy of the model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(score, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Add the accuracy to the summary\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(filewriter_path)\n",
    "\n",
    "# Initialize an saver for store model checkpoints\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Get the number of training/validation steps per epoch\n",
    "train_batches_per_epoch = int(np.floor(tr_data.data_size/batch_size))\n",
    "val_batches_per_epoch = int(np.floor(val_data.data_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:19:33.012891 Start training...\n",
      "2018-05-31 05:19:33.013025 Open Tensorboard at --logdir /tensorboard\n",
      "2018-05-31 05:19:33.013062 Epoch number: 1\n",
      "2018-05-31 05:19:38.065785 step\n",
      "2018-05-31 05:19:41.961362 step\n",
      "2018-05-31 05:19:45.695185 step\n",
      "2018-05-31 05:19:47.627632 Start validation\n",
      "2018-05-31 05:19:48.129277 Validation Accuracy = 0.6719\n",
      "2018-05-31 05:19:48.129448 Saving checkpoint of model...\n",
      "2018-05-31 05:19:48.393550 Model checkpoint saved at /checkpoints/model_epoch1.ckpt\n",
      "2018-05-31 05:19:48.393937 Epoch number: 2\n",
      "2018-05-31 05:19:51.805003 step\n",
      "2018-05-31 05:19:55.431014 step\n",
      "2018-05-31 05:19:59.183862 step\n",
      "2018-05-31 05:20:01.117211 Start validation\n",
      "2018-05-31 05:20:01.575386 Validation Accuracy = 0.4562\n",
      "2018-05-31 05:20:01.575561 Saving checkpoint of model...\n",
      "2018-05-31 05:20:01.802945 Model checkpoint saved at /checkpoints/model_epoch2.ckpt\n",
      "2018-05-31 05:20:01.803696 Epoch number: 3\n",
      "2018-05-31 05:20:05.263267 step\n",
      "2018-05-31 05:20:09.026249 step\n",
      "2018-05-31 05:20:12.771274 step\n",
      "2018-05-31 05:20:14.705133 Start validation\n",
      "2018-05-31 05:20:15.154918 Validation Accuracy = 0.4938\n",
      "2018-05-31 05:20:15.155029 Saving checkpoint of model...\n",
      "2018-05-31 05:20:15.375168 Model checkpoint saved at /checkpoints/model_epoch3.ckpt\n",
      "2018-05-31 05:20:15.375378 Epoch number: 4\n",
      "2018-05-31 05:20:18.799939 step\n",
      "2018-05-31 05:20:22.535581 step\n",
      "2018-05-31 05:20:26.263015 step\n",
      "2018-05-31 05:20:28.203734 Start validation\n",
      "2018-05-31 05:20:28.666038 Validation Accuracy = 0.4125\n",
      "2018-05-31 05:20:28.666204 Saving checkpoint of model...\n",
      "2018-05-31 05:20:28.892801 Model checkpoint saved at /checkpoints/model_epoch4.ckpt\n",
      "2018-05-31 05:20:28.893025 Epoch number: 5\n",
      "2018-05-31 05:20:32.361180 step\n",
      "2018-05-31 05:20:36.061552 step\n",
      "2018-05-31 05:20:39.815221 step\n",
      "2018-05-31 05:20:41.752083 Start validation\n",
      "2018-05-31 05:20:42.203716 Validation Accuracy = 0.6719\n",
      "2018-05-31 05:20:42.203935 Saving checkpoint of model...\n",
      "2018-05-31 05:20:42.414322 Model checkpoint saved at /checkpoints/model_epoch5.ckpt\n",
      "2018-05-31 05:20:42.414526 Epoch number: 6\n",
      "2018-05-31 05:20:45.801132 step\n",
      "2018-05-31 05:20:49.609289 step\n",
      "2018-05-31 05:20:53.399124 step\n",
      "2018-05-31 05:20:55.325296 Start validation\n",
      "2018-05-31 05:20:55.737069 Validation Accuracy = 0.6875\n",
      "2018-05-31 05:20:55.737277 Saving checkpoint of model...\n",
      "2018-05-31 05:20:55.990632 Model checkpoint saved at /checkpoints/model_epoch6.ckpt\n",
      "2018-05-31 05:20:55.990857 Epoch number: 7\n",
      "2018-05-31 05:20:59.394285 step\n",
      "2018-05-31 05:21:03.062556 step\n",
      "2018-05-31 05:21:06.790368 step\n",
      "2018-05-31 05:21:08.721619 Start validation\n",
      "2018-05-31 05:21:09.119035 Validation Accuracy = 0.4719\n",
      "2018-05-31 05:21:09.119198 Saving checkpoint of model...\n",
      "2018-05-31 05:21:09.359354 Model checkpoint saved at /checkpoints/model_epoch7.ckpt\n",
      "2018-05-31 05:21:09.359567 Epoch number: 8\n",
      "2018-05-31 05:21:12.768417 step\n",
      "2018-05-31 05:21:16.431244 step\n",
      "2018-05-31 05:21:20.194316 step\n",
      "2018-05-31 05:21:22.125746 Start validation\n",
      "2018-05-31 05:21:22.538460 Validation Accuracy = 0.5656\n",
      "2018-05-31 05:21:22.538668 Saving checkpoint of model...\n",
      "2018-05-31 05:21:22.804648 Model checkpoint saved at /checkpoints/model_epoch8.ckpt\n",
      "2018-05-31 05:21:22.805213 Epoch number: 9\n",
      "2018-05-31 05:21:26.239538 step\n",
      "2018-05-31 05:21:30.013110 step\n",
      "2018-05-31 05:21:33.814740 step\n",
      "2018-05-31 05:21:35.762360 Start validation\n",
      "2018-05-31 05:21:36.158193 Validation Accuracy = 0.3906\n",
      "2018-05-31 05:21:36.158299 Saving checkpoint of model...\n",
      "2018-05-31 05:21:36.406791 Model checkpoint saved at /checkpoints/model_epoch9.ckpt\n",
      "2018-05-31 05:21:36.407025 Epoch number: 10\n",
      "2018-05-31 05:21:39.790476 step\n",
      "2018-05-31 05:21:43.442674 step\n",
      "2018-05-31 05:21:47.154658 step\n",
      "2018-05-31 05:21:49.078984 Start validation\n",
      "2018-05-31 05:21:49.541070 Validation Accuracy = 0.4250\n",
      "2018-05-31 05:21:49.541209 Saving checkpoint of model...\n",
      "2018-05-31 05:21:49.803741 Model checkpoint saved at /checkpoints/model_epoch10.ckpt\n",
      "2018-05-31 05:21:49.803963 Epoch number: 11\n",
      "2018-05-31 05:21:53.313535 step\n",
      "2018-05-31 05:21:56.967909 step\n",
      "2018-05-31 05:22:00.718699 step\n",
      "2018-05-31 05:22:02.641847 Start validation\n",
      "2018-05-31 05:22:03.096606 Validation Accuracy = 0.3219\n",
      "2018-05-31 05:22:03.096829 Saving checkpoint of model...\n",
      "2018-05-31 05:22:03.362108 Model checkpoint saved at /checkpoints/model_epoch11.ckpt\n",
      "2018-05-31 05:22:03.362329 Epoch number: 12\n",
      "2018-05-31 05:22:06.879678 step\n",
      "2018-05-31 05:22:10.725493 step\n",
      "2018-05-31 05:22:14.478585 step\n",
      "2018-05-31 05:22:16.384309 Start validation\n",
      "2018-05-31 05:22:16.817766 Validation Accuracy = 0.5219\n",
      "2018-05-31 05:22:16.817981 Saving checkpoint of model...\n",
      "2018-05-31 05:22:17.059570 Model checkpoint saved at /checkpoints/model_epoch12.ckpt\n",
      "2018-05-31 05:22:17.059765 Epoch number: 13\n",
      "2018-05-31 05:22:20.459017 step\n",
      "2018-05-31 05:22:24.165751 step\n",
      "2018-05-31 05:22:27.951321 step\n",
      "2018-05-31 05:22:29.874954 Start validation\n",
      "2018-05-31 05:22:30.278576 Validation Accuracy = 0.3000\n",
      "2018-05-31 05:22:30.278704 Saving checkpoint of model...\n",
      "2018-05-31 05:22:30.578631 Model checkpoint saved at /checkpoints/model_epoch13.ckpt\n",
      "2018-05-31 05:22:30.578822 Epoch number: 14\n",
      "2018-05-31 05:22:33.997805 step\n",
      "2018-05-31 05:22:37.658451 step\n",
      "2018-05-31 05:22:41.424835 step\n",
      "2018-05-31 05:22:43.446851 Start validation\n",
      "2018-05-31 05:22:43.851332 Validation Accuracy = 0.4125\n",
      "2018-05-31 05:22:43.851528 Saving checkpoint of model...\n",
      "2018-05-31 05:22:44.095398 Model checkpoint saved at /checkpoints/model_epoch14.ckpt\n",
      "2018-05-31 05:22:44.095608 Epoch number: 15\n",
      "2018-05-31 05:22:47.544346 step\n",
      "2018-05-31 05:22:51.437640 step\n",
      "2018-05-31 05:22:55.291923 step\n",
      "2018-05-31 05:22:57.253623 Start validation\n",
      "2018-05-31 05:22:57.661164 Validation Accuracy = 0.4906\n",
      "2018-05-31 05:22:57.661298 Saving checkpoint of model...\n",
      "2018-05-31 05:22:57.909882 Model checkpoint saved at /checkpoints/model_epoch15.ckpt\n",
      "2018-05-31 05:22:57.910082 Epoch number: 16\n",
      "2018-05-31 05:23:01.398042 step\n",
      "2018-05-31 05:23:05.364088 step\n",
      "2018-05-31 05:23:09.253481 step\n",
      "2018-05-31 05:23:11.249001 Start validation\n",
      "2018-05-31 05:23:11.711089 Validation Accuracy = 0.4156\n",
      "2018-05-31 05:23:11.711322 Saving checkpoint of model...\n",
      "2018-05-31 05:23:11.966817 Model checkpoint saved at /checkpoints/model_epoch16.ckpt\n",
      "2018-05-31 05:23:11.967045 Epoch number: 17\n",
      "2018-05-31 05:23:15.447583 step\n",
      "2018-05-31 05:23:19.295021 step\n",
      "2018-05-31 05:23:23.187877 step\n",
      "2018-05-31 05:23:25.334054 Start validation\n",
      "2018-05-31 05:23:25.818331 Validation Accuracy = 0.3156\n",
      "2018-05-31 05:23:25.818534 Saving checkpoint of model...\n",
      "2018-05-31 05:23:26.073001 Model checkpoint saved at /checkpoints/model_epoch17.ckpt\n",
      "2018-05-31 05:23:26.073228 Epoch number: 18\n",
      "2018-05-31 05:23:29.560246 step\n",
      "2018-05-31 05:23:33.380320 step\n",
      "2018-05-31 05:23:37.225580 step\n",
      "2018-05-31 05:23:39.238604 Start validation\n",
      "2018-05-31 05:23:39.698640 Validation Accuracy = 0.6344\n",
      "2018-05-31 05:23:39.698843 Saving checkpoint of model...\n",
      "2018-05-31 05:23:39.955722 Model checkpoint saved at /checkpoints/model_epoch18.ckpt\n",
      "2018-05-31 05:23:39.955941 Epoch number: 19\n",
      "2018-05-31 05:23:43.356062 step\n",
      "2018-05-31 05:23:47.186660 step\n",
      "2018-05-31 05:23:51.021772 step\n",
      "2018-05-31 05:23:52.979066 Start validation\n",
      "2018-05-31 05:23:53.418588 Validation Accuracy = 0.4844\n",
      "2018-05-31 05:23:53.418739 Saving checkpoint of model...\n",
      "2018-05-31 05:23:53.663691 Model checkpoint saved at /checkpoints/model_epoch19.ckpt\n",
      "2018-05-31 05:23:53.663884 Epoch number: 20\n",
      "2018-05-31 05:23:57.131081 step\n",
      "2018-05-31 05:24:00.749212 step\n",
      "2018-05-31 05:24:04.576908 step\n",
      "2018-05-31 05:24:06.520849 Start validation\n",
      "2018-05-31 05:24:07.009467 Validation Accuracy = 0.3656\n",
      "2018-05-31 05:24:07.009684 Saving checkpoint of model...\n",
      "2018-05-31 05:24:07.276624 Model checkpoint saved at /checkpoints/model_epoch20.ckpt\n",
      "2018-05-31 05:24:07.277376 Epoch number: 21\n",
      "2018-05-31 05:24:10.724250 step\n",
      "2018-05-31 05:24:14.555870 step\n",
      "2018-05-31 05:24:18.321468 step\n",
      "2018-05-31 05:24:20.301856 Start validation\n",
      "2018-05-31 05:24:20.778229 Validation Accuracy = 0.3219\n",
      "2018-05-31 05:24:20.778445 Saving checkpoint of model...\n",
      "2018-05-31 05:24:21.046965 Model checkpoint saved at /checkpoints/model_epoch21.ckpt\n",
      "2018-05-31 05:24:21.047186 Epoch number: 22\n",
      "2018-05-31 05:24:24.497662 step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 05:24:28.233898 step\n",
      "2018-05-31 05:24:31.969512 step\n",
      "2018-05-31 05:24:33.930165 Start validation\n",
      "2018-05-31 05:24:34.337988 Validation Accuracy = 0.3219\n",
      "2018-05-31 05:24:34.338132 Saving checkpoint of model...\n",
      "2018-05-31 05:24:34.601905 Model checkpoint saved at /checkpoints/model_epoch22.ckpt\n",
      "2018-05-31 05:24:34.602123 Epoch number: 23\n",
      "2018-05-31 05:24:38.019201 step\n",
      "2018-05-31 05:24:41.745615 step\n",
      "2018-05-31 05:24:45.549293 step\n",
      "2018-05-31 05:24:47.469208 Start validation\n",
      "2018-05-31 05:24:47.915497 Validation Accuracy = 0.3719\n",
      "2018-05-31 05:24:47.915696 Saving checkpoint of model...\n",
      "2018-05-31 05:24:48.167840 Model checkpoint saved at /checkpoints/model_epoch23.ckpt\n",
      "2018-05-31 05:24:48.168035 Epoch number: 24\n",
      "2018-05-31 05:24:51.696683 step\n",
      "2018-05-31 05:24:55.582174 step\n",
      "2018-05-31 05:24:59.473284 step\n",
      "2018-05-31 05:25:01.562885 Start validation\n",
      "2018-05-31 05:25:02.000472 Validation Accuracy = 0.4281\n",
      "2018-05-31 05:25:02.000585 Saving checkpoint of model...\n",
      "2018-05-31 05:25:02.268880 Model checkpoint saved at /checkpoints/model_epoch24.ckpt\n",
      "2018-05-31 05:25:02.269104 Epoch number: 25\n",
      "2018-05-31 05:25:05.742465 step\n",
      "2018-05-31 05:25:09.416626 step\n",
      "2018-05-31 05:25:13.193801 step\n",
      "2018-05-31 05:25:15.200305 Start validation\n",
      "2018-05-31 05:25:15.610368 Validation Accuracy = 0.3625\n",
      "2018-05-31 05:25:15.610926 Saving checkpoint of model...\n",
      "2018-05-31 05:25:15.871409 Model checkpoint saved at /checkpoints/model_epoch25.ckpt\n",
      "2018-05-31 05:25:15.871696 Epoch number: 26\n",
      "2018-05-31 05:25:19.307320 step\n",
      "2018-05-31 05:25:23.062208 step\n",
      "2018-05-31 05:25:26.797307 step\n",
      "2018-05-31 05:25:28.708553 Start validation\n",
      "2018-05-31 05:25:29.150411 Validation Accuracy = 0.3187\n",
      "2018-05-31 05:25:29.150552 Saving checkpoint of model...\n",
      "2018-05-31 05:25:29.592717 Model checkpoint saved at /checkpoints/model_epoch26.ckpt\n",
      "2018-05-31 05:25:29.592907 Epoch number: 27\n",
      "2018-05-31 05:25:32.997691 step\n",
      "2018-05-31 05:25:36.779760 step\n",
      "2018-05-31 05:25:40.638078 step\n",
      "2018-05-31 05:25:42.607165 Start validation\n",
      "2018-05-31 05:25:43.067940 Validation Accuracy = 0.4844\n",
      "2018-05-31 05:25:43.068096 Saving checkpoint of model...\n",
      "2018-05-31 05:25:43.547555 Model checkpoint saved at /checkpoints/model_epoch27.ckpt\n",
      "2018-05-31 05:25:43.547862 Epoch number: 28\n",
      "2018-05-31 05:25:46.998071 step\n",
      "2018-05-31 05:25:50.798098 step\n",
      "2018-05-31 05:25:54.634307 step\n",
      "2018-05-31 05:25:56.692733 Start validation\n",
      "2018-05-31 05:25:57.138506 Validation Accuracy = 0.5062\n",
      "2018-05-31 05:25:57.138669 Saving checkpoint of model...\n",
      "2018-05-31 05:25:57.604975 Model checkpoint saved at /checkpoints/model_epoch28.ckpt\n",
      "2018-05-31 05:25:57.605203 Epoch number: 29\n",
      "2018-05-31 05:26:01.063815 step\n",
      "2018-05-31 05:26:04.827116 step\n",
      "2018-05-31 05:26:08.697255 step\n",
      "2018-05-31 05:26:10.676799 Start validation\n",
      "2018-05-31 05:26:11.152575 Validation Accuracy = 0.4188\n",
      "2018-05-31 05:26:11.152799 Saving checkpoint of model...\n",
      "2018-05-31 05:26:11.624631 Model checkpoint saved at /checkpoints/model_epoch29.ckpt\n",
      "2018-05-31 05:26:11.624870 Epoch number: 30\n",
      "2018-05-31 05:26:15.059201 step\n",
      "2018-05-31 05:26:18.732995 step\n",
      "2018-05-31 05:26:22.450876 step\n",
      "2018-05-31 05:26:24.351941 Start validation\n",
      "2018-05-31 05:26:24.756016 Validation Accuracy = 0.3531\n",
      "2018-05-31 05:26:24.756218 Saving checkpoint of model...\n",
      "2018-05-31 05:26:25.204116 Model checkpoint saved at /checkpoints/model_epoch30.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Start Tensorflow session\n",
    "config=tf.ConfigProto(allow_soft_placement = True)\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # Load the pretrained weights into the non-trainable layer\n",
    "    model.load_initial_weights(sess)\n",
    "\n",
    "    print(\"{} Start training...\".format(datetime.now()))\n",
    "    print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(),\n",
    "                                                      filewriter_path))\n",
    "\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(\"{} Epoch number: {}\".format(datetime.now(), epoch+1))\n",
    "\n",
    "        # Initialize iterator with the training dataset\n",
    "        sess.run(training_init_op)\n",
    "\n",
    "        for step in range(train_batches_per_epoch):\n",
    "\n",
    "            # get next batch of data\n",
    "            img_batch, label_batch = sess.run(next_batch)       \n",
    "\n",
    "            # And run the training op\n",
    "            sess.run(train_op, feed_dict={x: img_batch,\n",
    "                                          y: label_batch,\n",
    "                                          keep_prob: dropout_rate})\n",
    "\n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            if step % display_step == 0:\n",
    "                s = sess.run(merged_summary, feed_dict={x: img_batch,\n",
    "                                                        y: label_batch,\n",
    "                                                        keep_prob: 1.})\n",
    "                writer.add_summary(s, epoch*train_batches_per_epoch + step)\n",
    "                print(\"{} step\".format(datetime.now(), step))\n",
    "\n",
    "        # Validate the model on the entire validation set\n",
    "        print(\"{} Start validation\".format(datetime.now()))\n",
    "        sess.run(validation_init_op)\n",
    "        test_acc = 0.\n",
    "        test_count = 0\n",
    "        for _ in range(val_batches_per_epoch):\n",
    "\n",
    "            img_batch, label_batch = sess.run(next_batch)\n",
    "            acc = sess.run(accuracy, feed_dict={x: img_batch,\n",
    "                                                y: label_batch,\n",
    "                                                keep_prob: 1.})\n",
    "            test_acc += acc\n",
    "            test_count += 1\n",
    "        test_acc /= test_count\n",
    "        print(\"{} Validation Accuracy = {:.4f}\".format(datetime.now(),\n",
    "                                                       test_acc))\n",
    "        print(\"{} Saving checkpoint of model...\".format(datetime.now()))\n",
    "\n",
    "        # save checkpoint of the model\n",
    "        checkpoint_name = os.path.join(checkpoint_path,\n",
    "                                       'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "        save_path = saver.save(sess, checkpoint_name)\n",
    "\n",
    "        print(\"{} Model checkpoint saved at {}\".format(datetime.now(),\n",
    "                                                       checkpoint_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
